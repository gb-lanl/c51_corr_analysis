{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gvar as gv\n",
    "import re \n",
    "# import pandas as pd \n",
    "import sys\n",
    "import copy\n",
    "import tables as h5\n",
    "import h5py\n",
    "import os \n",
    "import time\n",
    "import collections\n",
    "# sys.path.insert(0,'home/gbradley/nucleon_elastic_FF')\n",
    "# sys.path.insert(0, '/Users/grantdb/nucleon_elastic_FF')\n",
    "sys.path.insert(0,'/Users/grantdb/lqcd/c51_corr_analysis')\n",
    "from src.h5io import get_dsets \n",
    "from src.parsing import parse_t_info, parse_file_info \n",
    "\n",
    "from src.concat import concatenate,concat_dsets\n",
    "# from nucleon_elastic_ff.data.scripts.concat import concat_dsets\n",
    "# from src.concat import concat_dsets\n",
    "from src.utils import group_files,parse_dset_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tsep': 10}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_ = (\n",
    "    '3pt_tsep10/NUCL_D_MIXED_NONREL_l0_g0/src5.0_snk5.0/qz+0_qy+0_qx+0/C13.b_5682/AMA'\n",
    ")\n",
    "pattern = {\"3pt\": '3pt',\n",
    "    \"_tsep(?P<tsep>[0-9][0-9]+)\":'',  # must match `_tsep` and stores the following numbers (any length)\n",
    "    \"/NUCL_(?P<quark>U|D)\":'',  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\":'',  # Not sure if this changes. Not stored for now\n",
    "    \"_l(?P<l>[0-9]+)\": '',  # action parameters?\n",
    "    \"_g(?P<g>[0-15]+)\":'',\n",
    "    \"src(?P<src>[0-9\\.]+)\\/\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\\/\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"qz(?P<qz>[\\+\\-0-9]+)\\/\":'', \n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\\/\":'', \n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\\/\":'',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''}\n",
    "\n",
    "# parse_dset_address(string,dset_replace_patterns=pattern)\n",
    "def get_tsep(string):\n",
    "    result = {}\n",
    "    match = re.search(r\"_tsep(?P<tsep>[0-9][0-9]+)\", string)\n",
    "    if match:\n",
    "            for key, val in match.groupdict().items():\n",
    "                result[key] = int(val)\n",
    "    return result\n",
    "get_tsep(string_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1816153862.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/51/q64yvfmn7fsfsg6cw1l6w8_00000kq/T/ipykernel_72942/1816153862.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    ):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def slice_file(\n",
    "    file_address_in: str,\n",
    "    file_address_out: str,\n",
    "    overwrite: bool = False,\n",
    "    tslice_fact: Optional[float] = None,\n",
    "    dset_patterns: List[str] = (\"local_current\",),\n",
    "    boundary_sign_flip: bool = False,\n",
    "):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsep\n",
      "quark\n",
      "l\n",
      "g\n",
      "src\n",
      "snk\n",
      "qz\n",
      "qy\n",
      "qx\n",
      "cfg\n"
     ]
    }
   ],
   "source": [
    "#h5fname = '/home/gbradley/c51_corr_analysis/tests/data/a09m135_s_avg_srcs0-15.h5'\n",
    "h5fname = '/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_4002.ama.h5'\n",
    "\n",
    "stringg='2pt/proton/src10.0_snk10.0/proton/E7.a_1716/AMA'\n",
    "# string='2pt/pion/src10.0_snk10.0/pion/E7.0_1716/AMA'\n",
    "dset_replace_patterns = {}\n",
    "dset_replace_patterns['pion'] = {\n",
    "    '2pt' : '2pt',\n",
    "    '(?P<corr>pion)':'pion',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "dset_replace_patterns['pion_SP'] = {\n",
    "    '2pt' : '2pt',\n",
    "    #'(?P<corr>pion|pion_SP|proton|proton_SP)':'corr',\n",
    "    '(?P<corr>pion_SP)':'pion_SP',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "dset_replace_patterns['proton'] = {\n",
    "    '2pt' : '2pt',\n",
    "    #'(?P<corr>pion|pion_SP|proton|proton_SP)':'corr',\n",
    "    '(?P<corr>proton)':'proton',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "dset_replace_patterns['proton_SP'] = {\n",
    "    '2pt' : '2pt',\n",
    "    #'(?P<corr>pion|pion_SP|proton|proton_SP)':'corr',\n",
    "    '(?P<corr>proton_SP)':'proton_SP',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "\n",
    "dset_replace_patterns['3pt'] = {\n",
    "    '3pt_tsep(?P<tsep>[0-9][0-9]+)' : '3pt',\n",
    "    \"/NUCL_(?P<quark>U|D)\" : '',  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\" : '',  # Not sure if this changes. Not stored for now\n",
    "    \"_l(?P<l>[0-9]+)\":'',  # action parameters?\n",
    "    \"_g(?P<g>[0-15]+)\":'',\n",
    "    \"/src(?P<src>[0-9\\.]+)\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"/qz(?P<qz>[\\+\\-0-9]+)\":'', \n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\":'', \n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\":'',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "}\n",
    "string_ = '3pt_tsep21/NUCL_D_MIXED_NONREL_l0_g0/src10.0_snk10.0/qz+0_qy+0_qx+0/E7.a_1716/AMA'\n",
    "out_grp,meta_info = parse_dset_address(string_,dset_replace_patterns=dset_replace_patterns['3pt'])\n",
    "for keys in meta_info.keys():\n",
    "    \n",
    "# for key in dset_parsed.keys():\n",
    "# out_grp,meta_info = parse_dset_address(stringg,dset_replace_patterns=dset_replace_patterns['proton'])\n",
    "# from src.parsing import parse_file_info\n",
    "# parse_file_info(string_)\n",
    "# print(out_grp,meta_info)\n",
    "# dset_replace_patterns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = 'E7'\n",
    "data_dir = '/home/gbradley/c51_corr_analysis/tests/data/E7/' #all configurations\n",
    "#data_dir = '/Users/grantdb/lqcd/c51_corr_analysis/tests/data/E7/'\n",
    "\n",
    "dirs = os.listdir( data_dir )\n",
    "cnf_abbr = [files.split(\".ama.h5\")[0] for files in dirs]\n",
    "cnf_abbr = [cnf.replace('-','.') for cnf in cnf_abbr]\n",
    "# cnf_abbr_ascend = {}\n",
    "cnf_abbr_ascend = [cnf_.split('_')[1] for cnf_ in cnf_abbr]\n",
    "cfg_abbr_sorted = np.sort(cnf_abbr_ascend,axis=None)\n",
    "with open(\"cfg.txt\",\"a\") as f: \n",
    "\n",
    "    print(cfg_abbr_sorted.astype(int).tolist(),file=f)\n",
    "# embed()\n",
    "data_file_list = list()\n",
    "for dirpath,_,filenames in os.walk(data_dir):\n",
    "    for f in filenames:\n",
    "        data_file_list.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "sorted_files = np.sort(data_file_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-04 18:14:46,397|nucleon_elastic_ff@INFO] Starting concatenating over `4` files with hdf5 group/dset substitutions\n",
      "[2022-09-04 18:14:46,398|nucleon_elastic_ff@INFO] \t'3pt_tsep(?P<tsep>[0-9][0-9]+)' = ''\n",
      "[2022-09-04 18:14:46,398|nucleon_elastic_ff@INFO] \t'/NUCL_(?P<quark>U|D)' = ''\n",
      "[2022-09-04 18:14:46,399|nucleon_elastic_ff@INFO] \t'_MIXED_NONREL' = ''\n",
      "[2022-09-04 18:14:46,400|nucleon_elastic_ff@INFO] \t'_l(?P<l>[0-9]+)' = ''\n",
      "[2022-09-04 18:14:46,400|nucleon_elastic_ff@INFO] \t'_g(?P<g>[0-15]+)' = ''\n",
      "[2022-09-04 18:14:46,403|nucleon_elastic_ff@INFO] \t'/src(?P<src>[0-9\\.]+)' = ''\n",
      "[2022-09-04 18:14:46,404|nucleon_elastic_ff@INFO] \t'_snk(?P<snk>[0-9\\.]+)' = ''\n",
      "[2022-09-04 18:14:46,405|nucleon_elastic_ff@INFO] \t'/qz(?P<qz>[\\+\\-0-9]+)' = ''\n",
      "[2022-09-04 18:14:46,405|nucleon_elastic_ff@INFO] \t'_qy(?P<qy>[\\+\\-0-9]+)' = ''\n",
      "[2022-09-04 18:14:46,406|nucleon_elastic_ff@INFO] \t'_qx(?P<qx>[\\+\\-0-9]+)' = ''\n",
      "[2022-09-04 18:14:46,406|nucleon_elastic_ff@INFO] \t'(?P<cfg>/E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/' = ''\n",
      "[2022-09-04 18:14:46,406|nucleon_elastic_ff@INFO] The export file will be called `/home/gbradley/c51_corr_analysis/src/fitter/3pt_tsep13.h5`\n",
      "[2022-09-04 18:14:46,406|nucleon_elastic_ff@INFO] Start parsing files\n",
      "[2022-09-04 18:14:46,407|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-a_1716.ama.h5`\n",
      "[2022-09-04 18:14:56,754|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_2216.ama.h5`\n",
      "[2022-09-04 18:15:07,509|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-b_1124.ama.h5`\n",
      "[2022-09-04 18:15:18,874|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_1964.ama.h5`\n",
      "[2022-09-04 18:15:30,856|nucleon_elastic_ff@INFO] Writing `4` dsets to `/home/gbradley/c51_corr_analysis/src/fitter/3pt_tsep13.h5`\n",
      "[2022-09-04 18:15:40,685|nucleon_elastic_ff@WARNING] Expected 4 but found 35280 dsets with same name for key `AMA`\n",
      "[2022-09-04 18:15:42,473|nucleon_elastic_ff@WARNING] Expected 4 but found 5880 dsets with same name for key `2AMA`\n",
      "[2022-09-04 18:15:44,142|nucleon_elastic_ff@WARNING] Expected 4 but found 5880 dsets with same name for key `3AMA`\n",
      "[2022-09-04 18:15:45,802|nucleon_elastic_ff@WARNING] Expected 4 but found 5880 dsets with same name for key `4AMA`\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'3pt_tsep15'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fb6e04f160cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# concat_dsets(data_file_list[0:4], out_file['proton_SP'], dset_replace_patterns=dset_replace_patterns['proton_SP'],overwrite=False,write_unpaired_dsets=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mconcat_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep13'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_unpaired_dsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mconcat_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep15'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep15'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_unpaired_dsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mconcat_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep17'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep17'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_unpaired_dsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mconcat_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep19'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3pt_tsep19'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_unpaired_dsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '3pt_tsep15'"
     ]
    }
   ],
   "source": [
    "\n",
    "# data_file_list = os.path.realpath(dirs)\n",
    "\n",
    "# embed()\n",
    "# file = data_file_list[0]\n",
    "# dset_replace_patterns = {'(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''}\n",
    "out_file = {}\n",
    "out_file['pion'] = os.path.join(os.getcwd(),\"pion.h5\")\n",
    "out_file['pion_SP'] = os.path.join(os.getcwd(),\"pion_SP.h5\")\n",
    "out_file['proton'] = os.path.join(os.getcwd(),\"proton.h5\")\n",
    "out_file['proton_SP'] = os.path.join(os.getcwd(),\"proton_SP.h5\")\n",
    "out_file['3pt_tsep13'] = os.path.join(os.getcwd(),\"3pt_tsep13.h5\")\n",
    "\n",
    "# TODO this needs to be in a loop, but not working with external module concat_dsets\n",
    "# for corr in dset_replace_patterns.keys():\n",
    "# concat_dsets(data_file_list[0:4], out_file['proton'], dset_replace_patterns=dset_replace_patterns['proton'],overwrite=False,write_unpaired_dsets=True)\n",
    "# concat_dsets(data_file_list[0:4], out_file['pion'], dset_replace_patterns=dset_replace_patterns['pion'],overwrite=False,write_unpaired_dsets=True)\n",
    "#concat_dsets(data_file_list[0:4], out_file['pion_SP'], dset_replace_patterns=dset_replace_patterns['pion_SP'],overwrite=False,write_unpaired_dsets=True)\n",
    "# concat_dsets(data_file_list[0:4], out_file['proton_SP'], dset_replace_patterns=dset_replace_patterns['proton_SP'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep13'], dset_replace_patterns=dset_replace_patterns['3pt'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep15'], dset_replace_patterns=dset_replace_patterns['3pt_tsep15'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep17'], dset_replace_patterns=dset_replace_patterns['3pt_tsep17'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep19'], dset_replace_patterns=dset_replace_patterns['3pt_tsep19'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep21'], dset_replace_patterns=dset_replace_patterns['3pt_tsep21'],overwrite=False,write_unpaired_dsets=True)\n",
    "\n",
    "# streams = {\n",
    "#     'E7' : ['0','a','b','c']\n",
    "# }\n",
    "# for i_s, s in enumerate(streams[ens]):\n",
    "#     f_in = h5.open_file(ens+'_'+s+'/'+data_dir+'/avg/'+ens+'_'+s+'_avg_srcs'+srcs[ens]+'.h5')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-04 22:57:24,910|lqcd correlator analysis@INFO] Locating all dsets of h5 file `example_data.hdf5`\n",
      "[2022-09-04 22:57:24,923|lqcd correlator analysis@INFO] Locating all dsets of h5 file `proton.h5`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1075, 96)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "h5f2 = h5py.File('proton.h5','r')\n",
    "h5f = h5py.File('example_data.hdf5','r')\n",
    "dsets = get_dsets(h5f)\n",
    "dsets2 = get_dsets(h5f2)\n",
    "# print(dsets)\n",
    "for dset in dsets2:\n",
    "\n",
    "    # corr = h5f[dset][:]\n",
    "    corr2 = h5f2[dset][:]\n",
    "# print(corr)\n",
    "print(corr.shape)\n",
    "print(corr2.shape)\n",
    "# corr_ = np.array(corr)\n",
    "corr_real = []\n",
    "corr_imag = []\n",
    "for i in range(len(corr)):\n",
    "    corr_real.append(corr[i][0])\n",
    "    corr_imag.append(corr[i][1])\n",
    "corr_out = {}\n",
    "corr_out['pion'] = np.array(corr_real)\n",
    "# corr_out[1:-1]\n",
    "# corr_out['pion']\n",
    "# print(gv.sdev(corr_out['pion']))\n",
    "\n",
    "import corr_functions as cf \n",
    "def _infer_tmax(ydata, noise_threshy):\n",
    "    \"\"\"Infer the maximum time with noise-to-signal below a threshold.\"\"\"\n",
    "    if noise_threshy is None:\n",
    "        return len(ydata) - 1\n",
    "    good = gv.sdev(ydata) / gv.mean(ydata) < noise_threshy\n",
    "    if np.all(good):\n",
    "        tmax = len(ydata) - 1\n",
    "    else:\n",
    "        tmax = np.argmin(good)\n",
    "    return tmax\n",
    "\n",
    "# _infer_tmax(corr_out['pion'],noise_threshy=0.02)\n",
    "\n",
    "\n",
    "# cf.C_2pt(tag='pion',ydata=corr_out['pion'])\n",
    "\n",
    "# # def bin(array,binsize=1):\n",
    "# #     if binsize <= 1:\n",
    "# #         return arrary\n",
    "\n",
    "# ordered_tags = sorted(corr_out.keys(), key=str)\n",
    "# try:\n",
    "#     sizes = [corr_out[tag].shape[0] for tag in ordered_tags]\n",
    "\n",
    "#     # sizes = [data[tag].shape[1] for tag in ordered_tags]\n",
    "# except IndexError:\n",
    "#         # edge case: single datum per sample\n",
    "#         sizes = [1 for tag in ordered_tags]\n",
    "# total_size = np.sum(sizes)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_mass(data):\n",
    "        \"\"\"\n",
    "        Computes the effective mass analytically using the following formula\n",
    "        \n",
    "        meff = ArcCosh( (C(t+1)+ C(t-1)) / C(t) )\n",
    "        This method correctly accounts for contributions both from forward- and\n",
    "        backward-propagating states. \n",
    "        \"\"\"\n",
    "        cosh_m = (data[2:] + data[:-2]) / (2.0 * data[1:-1])\n",
    "        meff = np.zeros(len(cosh_m), dtype=gv._gvarcore.GVar)\n",
    "        # The domain of arccosh is [1, Infinity).\n",
    "        # Set entries outside of the domain to nans.\n",
    "        domain = (cosh_m > 1)\n",
    "        meff[domain] = np.arccosh(cosh_m[domain])\n",
    "        meff[~domain] = gv.gvar(np.nan)\n",
    "        return meff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BufferDict({('pion', 'pion'): array([[1.14581642e-15]])})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# effective_mass(corr_out)v.mean(corr_out)\n",
    "#def build_dataset():\n",
    "mean = gv.mean(gv.dataset.avg_data(corr_out))\n",
    "binned = {tag:corr_out[tag] for tag in ordered_tags}\n",
    "binned_covariance = gv.evalcov(gv.dataset.avg_data(binned))\n",
    "binned_covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-190f0e16a7a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorr_functions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc2_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_2pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pion'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/c51_corr_analysis/src/fitter/corr_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tag, ydata, noise_threshy, skip_fastfit, **time_kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mtdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtime_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_tmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_threshy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Estimate the ground-state energy and amplitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskip_fastfit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/c51_corr_analysis/src/fitter/corr_functions.py\u001b[0m in \u001b[0;36m_infer_tmax\u001b[0;34m(ydata, noise_threshy)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnoise_threshy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mgood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnoise_threshy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_utilities.pyx\u001b[0m in \u001b[0;36mgvar._utilities.sdev\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_utilities.pyx\u001b[0m in \u001b[0;36mgvar._utilities.var\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division"
     ]
    }
   ],
   "source": [
    "import corr_functions as cf \n",
    "data_ = corr_out.pop('pion')\n",
    "c2_src = cf.C_2pt('pion',data_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corr in ['proton']:\n",
    "    for parity in ['','_SP']:\n",
    "        print(corr,parity)\n",
    "        for i_s,s in enumerate(streams[ens]):\n",
    "            f_in = h5.open_file(ens+'_'+s+'/'+data_dir+'/avg/'+ens+'_'+s+'_avg_srcs'+srcs[ens]+'.h5')\n",
    "            if s == streams[ens][0]:\n",
    "                su = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_up').read()\n",
    "                sd = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_dn').read()\n",
    "                cs = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/cfgs_srcs').read()\n",
    "            else:\n",
    "                tmp_su = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_up').read()\n",
    "                tmp_sd = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_dn').read()\n",
    "                tmp_cs = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/cfgs_srcs').read()\n",
    "                tmp_cs[:,0] += i_s * cs_offset[ens]\n",
    "                su = np.concatenate((su,tmp_su),axis=0)\n",
    "                sd = np.concatenate((sd,tmp_sd),axis=0)\n",
    "                cs = np.concatenate((cs,tmp_cs),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tsep': '10', 'quark': 'D', 'l': '0', 'g': '0', 'src': '5.0', 'snk': '5.0', 'qz': '+0', 'qy': '+0', 'qx': '+2'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "patterns = [\n",
    "    \"3pt\",\n",
    "    \"_tsep(?P<tsep>[0-9]|[0-9]+)\",  # must match `_tsep` and stores the following numbers (any length)\n",
    "    \"/NUCL_(?P<quark>U|D)\",  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\",  # Not sure if this changes. Not stored for now\n",
    "    \"_l(?P<l>[0-9]+)\",  # action parameters?\n",
    "    \"_g(?P<g>[0-15]+)\",\n",
    "    \"/src(?P<src>[0-9\\.]+)\",  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\",  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"/qz(?P<qz>[\\+\\-0-9]+)\", \n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\", \n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\", \n",
    "    \n",
    "]\n",
    "for n in range(len(patterns)):\n",
    "    pattern = \"\".join(patterns[:n+1])\n",
    "    match = re.match(pattern, string)\n",
    "    if not match:\n",
    "        print(pattern)\n",
    "        break\n",
    "\n",
    "if match:\n",
    "    print(match.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = [\"nucleon\", \"current\", \"tsep\", \"cfg\", \"t\", \"isospin\", \"parity\", \"spin\", \"corr\"]\n",
    "columns = [\"tsep\", \"quark\", \"l\", \"g\", \"src\", \"snk\",\"qz\",\"qy\",\"qx\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-24 15:48:53,566|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_4002.ama.h5`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tsep</th>\n",
       "      <th>quark</th>\n",
       "      <th>l</th>\n",
       "      <th>g</th>\n",
       "      <th>src</th>\n",
       "      <th>snk</th>\n",
       "      <th>qz</th>\n",
       "      <th>qy</th>\n",
       "      <th>qx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tsep quark  l  g  src  snk  qz  qy  qx\n",
       "0     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "1     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "2     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "3     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "4     8     D  0  0  5.0  5.0  +0  +0  +0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames = []\n",
    "\n",
    "with h5py.File(h5fname, \"r\") as h5f:\n",
    "    dsets = get_dsets(h5f)\n",
    "    # print(dsets)\n",
    "\n",
    "    for key, dset in dsets.items():\n",
    "        match = re.search(pattern, key)\n",
    "        if match:\n",
    "            info = match.groupdict()\n",
    "            # print(info)\n",
    "\n",
    "            # nucleon_parity = info.pop(\"parity\").split(\"_\")\n",
    "            g = info.pop(\"g\").split(\"_\")\n",
    "            # print(g)\n",
    "            info[\"g\"] = g[0]\n",
    "            # info[\"nucleon\"] = nucleon_parity[0]\n",
    "            # info[\"parity\"] = -1 if len(nucleon_parity) == 2 else 1\n",
    "            \n",
    "            # isospin = info.pop(\"isospin\")\n",
    "            # info[\"isospin\"] = 1 if isospin == \"UU\" else -1            \n",
    "\n",
    "            # current_key = key.replace(\"cfgs_srcs\", \"local_curr\")\n",
    "            curr_dset = h5f[key]\n",
    "            # print(curr_dset)\n",
    "            # print(curr_dset[0])\n",
    "            # print(curr_dset[0][0])\n",
    "\n",
    "            cfgs = dset[:]\n",
    "            # print(cfgs)\n",
    "            # print(cfgs[0])\n",
    "            corr = (\n",
    "                curr_dset[:][0] if info[\"g\"] in [\"g1\",\"g2\",\"g4\",\"g8\"] else curr_dset[:][1]\n",
    "            )\n",
    "            \n",
    "#             # print(corr)\n",
    "            ts = range(len(corr))\n",
    "#             # print(ts)\n",
    "#             # ts = range(corr.shape[-1])\n",
    "\n",
    "            tmp_df = (\n",
    "                pd.DataFrame(index=cfgs, columns=ts, data=corr)\n",
    "                .unstack()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"level_0\": \"t\", \"level_1\": \"cfg\", 0: \"corr\"})\n",
    "            )\n",
    "            # print(tmp_df)\n",
    "            for key, val in info.items():\n",
    "                tmp_df[key] = val\n",
    "            data_frames.append(tmp_df.astype({\"tsep\": int}))\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat(\n",
    "    data_frames, \n",
    "    ignore_index=True, \n",
    ").reindex(columns, axis=1).sort_values(columns).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleon</th>\n",
       "      <th>current</th>\n",
       "      <th>tsep</th>\n",
       "      <th>cfg</th>\n",
       "      <th>t</th>\n",
       "      <th>isospin</th>\n",
       "      <th>parity</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.123843e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.496932e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.118381e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.362174e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.552208e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nucleon current  tsep   cfg  t  isospin  parity          corr\n",
       "0  proton      A3     3  78.0  0       -1      -1  7.123843e-10\n",
       "1  proton      A3     3  78.0  0       -1       1 -5.496932e-10\n",
       "2  proton      A3     3  78.0  0        1      -1  1.118381e-09\n",
       "3  proton      A3     3  78.0  0        1       1 -8.362174e-10\n",
       "4  proton      A3     3  78.0  1       -1      -1  9.552208e-10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spin_avg_df = df.groupby(\n",
    "    [\"nucleon\", \"current\", \"tsep\", \"cfg\", \"t\", \"isospin\", \"parity\"], as_index=False\n",
    ")[\"corr\"].mean()\n",
    "\n",
    "spin_avg_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleon</th>\n",
       "      <th>current</th>\n",
       "      <th>tsep</th>\n",
       "      <th>cfg</th>\n",
       "      <th>t</th>\n",
       "      <th>isospin</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6.310388e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.772991e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6.853185e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.990430e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6.418973e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nucleon current  tsep   cfg  t  isospin          corr\n",
       "0  proton      A3     3  78.0  0       -1 -6.310388e-10\n",
       "1  proton      A3     3  78.0  0        1 -9.772991e-10\n",
       "2  proton      A3     3  78.0  1       -1 -6.853185e-10\n",
       "3  proton      A3     3  78.0  1        1 -5.990430e-10\n",
       "4  proton      A3     3  78.0  2       -1 -6.418973e-10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = spin_avg_df.copy()\n",
    "tmp[\"corr\"] *= tmp[\"parity\"]\n",
    "spin_parity_avg_df = tmp.groupby(\n",
    "    [\"nucleon\", \"current\", \"tsep\", \"cfg\", \"t\", \"isospin\",  ], as_index=False\n",
    ")[[\"corr\"]].mean()\n",
    "\n",
    "spin_parity_avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleon</th>\n",
       "      <th>current</th>\n",
       "      <th>tsep</th>\n",
       "      <th>cfg</th>\n",
       "      <th>t</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.462603e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.627543e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.859727e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.257450e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.371521e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nucleon current  tsep   cfg  t          corr\n",
       "0  proton      A3     3  78.0  0 -3.462603e-10\n",
       "1  proton      A3     3  78.0  1  8.627543e-11\n",
       "2  proton      A3     3  78.0  2  2.859727e-10\n",
       "3  proton      A3     3  78.0  3  4.257450e-11\n",
       "4  proton      A3     3  84.0  0  5.371521e-10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = spin_parity_avg_df.copy()\n",
    "tmp[\"corr\"] *= tmp[\"isospin\"]\n",
    "isospin_spin_parity_avg_df = (\n",
    "    tmp.groupby([\"nucleon\", \"current\", \"tsep\", \"cfg\",  \"t\"], as_index=False)[\"corr\"]\n",
    "    .sum()\n",
    ")\n",
    "isospin_spin_parity_avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_data(arg):\n",
    "    corr_avg = gv.dataset.avg_data(\n",
    "        arg.pivot(index=\"cfg\", columns=\"t\", values=\"corr\").values\n",
    "    )\n",
    "    return pd.Series(corr_avg)\n",
    "\n",
    "\n",
    "group = isospin_spin_parity_avg_df.groupby([\"nucleon\", \"current\", \"tsep\"])\n",
    "corr_df = (\n",
    "    group.apply(avg_data)\n",
    "    .reset_index(level=-1)\n",
    "    .rename(columns={\"level_3\": \"t\", 0: \"corr\"})\n",
    "    .reset_index()\n",
    "    .set_index([\"nucleon\", \"current\", \"tsep\", \"t\"])\n",
    ")\n",
    "# # print(corr_df)\n",
    "# corr_out = corr_df.to_dict(orient='tight')\n",
    "# # print(corr_out)\n",
    "# test = corr_df.loc[('proton', 'A3'),'corr']\n",
    "# test_src = \n",
    "# out = test.to_dict()\n",
    "# ydict = {tag: val for tag,val in out.items() if isinstance(tag,tuple)}\n",
    "# # print(ydict)\n",
    "# t_snk = list()\n",
    "# for item in out.keys():\n",
    "#     if item[0] not in t_snk:\n",
    "#         t_snk.append(item[0])\n",
    "# print(t_snk)\n",
    "# import fitter.corr_functions as cf \n",
    "# c3 = cf.C_3pt(tag='proton',ydata_3pt=ydict)\n",
    "# print(c3)\n",
    "# # # print(out)\n",
    "# # list(out.keys())\n",
    "# # [i[0] for i in out.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fitter.test_corr' has no attribute 'C2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-84e84db94949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_corr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fitter.test_corr' has no attribute 'C2'"
     ]
    }
   ],
   "source": [
    "\n",
    "Nstates = collections.namedtuple('NStates', ['n', 'no', 'm', 'mo'], defaults=(2, 1, 2, 1))\n",
    "def test_NPoint(tag,data,prior): #prior\n",
    "    \"\"\"Test cf.C_2pt and cf.C_3pt class.\"\"\"\n",
    "    # print(data[tag].shape)\n",
    "    nt = data[tag].shape\n",
    "    # print(corr)\n",
    "    data_ = data.pop(tag)\n",
    "    c2_src = cf.C_2pt(tag, data_)\n",
    "    \n",
    "    # print(len(c2_src.meff(avg=True)))\n",
    "    # model =get_two_point_model(c2_src)\n",
    "    # t_start = c2_src.times.tmin \n",
    "    # t_end = c2_src.times.tmax\n",
    "    # Nstates = collections.namedtuple('NStates', ['n', 'no', 'm', 'mo'], defaults=(1, 0, 0, 0))\n",
    "    nstates = Nstates(n=2, no=1)\n",
    "    # prior = priors.MesonPriorPDG(nstates, 'pi',a_fm = .09)\n",
    "    # fitter = C_2pt_Analysis(c2_src)\n",
    "    # fit = fitter.run_fit()\n",
    "\n",
    "    # fit = fitter.run_fit()\n",
    "\n",
    "    # c2.__setitem__\n",
    "    # c2_src[0] = 1.0\n",
    "    # print(fit)\n",
    "   \n",
    "    return c2_src\n",
    "def test_NPoint_snk(tag,data,prior):\n",
    "    # tag = 'PS'\n",
    "    nt = data[tag].shape\n",
    "    data_ = data.pop(tag)\n",
    "    c2_snk = cf.C_2pt(tag, data_)\n",
    "    # print(c2_snk)\n",
    "    # assert len(c2_snk) == nt[0],\\\n",
    "    #     \"Unexpected len(c2_snk)\"\n",
    "    # assert len(c2_snk[:]) == nt[0],\\\n",
    "    #     \"Unexpected len(c2_snk[:])\"\n",
    "    # Nstates = collections.namedtuple('NStates', ['n', 'no', 'm', 'mo'], defaults=(1, 0, 0, 0))\n",
    "    nstates = Nstates(n=2, no=1)\n",
    "    # n=nstates.n, no=nstates.no\n",
    "    # prior = priors.MesonPriorPDG(nstates, 'pi',a_fm = .09)\n",
    "    \n",
    "    # fitter = C_2pt_Analysis(c2_snk)\n",
    "    # fit = fitter.run_fit()\n",
    "    # print(fit)\n",
    "    \n",
    "    return c2_snk\n",
    "\n",
    "def test_NPoint_3pt(tag,data,c2,c2_src,c2_snk):\n",
    "    # nt = data[tag].shape\n",
    "    # print(nt)\n",
    "\n",
    "    data = data.pop(tag)\n",
    "    c3 = cf.C_3pt(tag, data)\n",
    "    # print(c3.ydict)\n",
    "    # avg = c3.avg(m_src=c2_src.mass, m_snk=c2_snk.mass)\n",
    "    # prior = priors.vmatrix(nstates)\n",
    "    # Nstates = collections.namedtuple('NStates', ['n', 'no', 'm', 'mo'], defaults=(1, 0, 0, 0))\n",
    "    nstates = Nstates(n=2, no=1,m=1,mo=0)\n",
    "    # print(nstates)\n",
    "    avg = c3.avg(m_src=c2_src.mass, m_snk=c2_snk.mass)\n",
    "    # print(avg)\n",
    "    # fitter = C_3pt_Analysis(data,c2,c2_snk,c2_src,tags=tag)\n",
    "    # fit = fitter.run_sequential_fits(nstates)\n",
    "    # print(fit)\n",
    "    return c3\n",
    "import fitter.test_corr as run \n",
    "print(run.C2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "t_sink keys must be integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-47350a447a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_sink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_sink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t_sink keys must be integers.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: t_sink keys must be integers."
     ]
    }
   ],
   "source": [
    "for t_sink in out.keys():\n",
    "    print(t_sink)\n",
    "    if not isinstance(t_sink, int):\n",
    "        raise TypeError(\"t_sink keys must be integers.\")\n",
    "    if nt is None:\n",
    "        try:\n",
    "            np.unique([len(arr) for arr in out.values()]).item()\n",
    "        except ValueError as _:\n",
    "            raise ValueError(\"Values in ydict must have same length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to Series, length must be 1: given 160",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2460c1fa4608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr_functions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_2pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'corr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/c51_corr_analysis/src/fitter/corr_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tag, ydata, noise_threshy, skip_fastfit, **time_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfastfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             self.fastfit = fastfit.FastFit(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mtp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/c51_corr_analysis/src/fitter/fastfit.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, ampl, dE, E, s, tp, tmin, svdcut, osc, nterm)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Marginalize over the exicted states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0md_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarginalized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Average over the remaining plateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__sub__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__rsub__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6948\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_prepare_scalar_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6950\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign_method_FRAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6952\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_frame_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36malign_method_FRAME\u001b[0;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mto_series\u001b[0;34m(right)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    240\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgiven_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to coerce to Series, length must be 1: given 160"
     ]
    }
   ],
   "source": [
    "import fitter.corr_functions as cf \n",
    "cf.C_2pt(tag='corr',ydata=corr_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/home/gbradley/c51_corr_analysis/tests/a09m135_s_avg_srcs0-15.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8fc4faa8384a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# top_keys = [key for key in h5f.keys()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# for top_key in top_keys:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 533\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/home/gbradley/c51_corr_analysis/tests/a09m135_s_avg_srcs0-15.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# h5fname = '/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_4002.ama.h5'\n",
    "\n",
    "\n",
    "   \n",
    "with h5py.File(h5fname, 'r') as h5f:\n",
    "    # top_keys = [key for key in h5f.keys()]\n",
    "    # for top_key in top_keys:\n",
    "    #     group = h5f[top_key]\n",
    "    #     group['10'] = group['3pt_tsep10']\n",
    "    data = {}\n",
    "    dsets = get_dsets(h5f)\n",
    "    # print(dsets)\n",
    "    for key in dsets.keys():\n",
    "        # print(key)\n",
    "        data[key] = h5f[key][:]\n",
    "    print(data['2pt/ext_current/src5.0_snk5.0/ext_axial_A1_A1/C13.b_4002/AMA'])\n",
    "    # [val for key,val in dsets.items() if key in mystring]\n",
    "    # print(val[key])\n",
    "    # for key in dsets.keys():\n",
    "    #     if key in \n",
    "        \n",
    "            \n",
    "    #     dset = ifile['data']\n",
    "    #     for key in dset.keys():\n",
    "    #         data[key] = ifile['data'][key][:]\n",
    "    # for key in ['13','14','15','16']:\n",
    "    #     data[int(key)] = data.pop(key)\n",
    "\n",
    "    # return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import fitter.corr_functions as cf\n",
    "# import fitter.fit_twopt\n",
    "\n",
    "directory = '/home/gbradley/c51_corr_analysis/tests/data/C13/'\n",
    "N_cnf = len([name for name in os.listdir(directory) if os.path.isfile(name)])\n",
    "\n",
    "dirs = os.listdir( directory )\n",
    "\n",
    "cnf_abbr = [files.split(\".ama.h5\",0) for files in dirs]\n",
    "\n",
    "# data_file_list = os.path.realpath(dirs)\n",
    "data_file_list = list()\n",
    "for dirpath,_,filenames in os.walk(directory):\n",
    "    for f in filenames:\n",
    "        data_file_list.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "file = data_file_list[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUCL: nucleon\n",
    "U: quark bilinear operator inserted on up-quark; D will be used for down-quark\n",
    "MIXED: \"mixed\" type of spin projection is used\n",
    "NONREL: non-relativistic proton is used\n",
    "l0:  when inserting the quark bilinear oprator, the separation of the quarks of the bilinear operator is zero (local operator); you might see some l1 (quark bilinear operator separated by 1 lattice unit) data as well\n",
    "g13: the gamma matrix of the quark bilinear operator is \"13\" in Chroma convention. Page 6 and 7 of the attached pdf shows the Chroma gamma matrix convention and its indexing; their indexing is summarized below:\n",
    " \n",
    "0: scalar; I\n",
    "15: pseudoscalar; g_5\n",
    "1: vector;  g_x\n",
    "2: vector;  g_y\n",
    "4: vector;  g_z\n",
    "8: vector;  g_t\n",
    "14: axial;   g_x g_5\n",
    "13: axial;  -g_y g_5\n",
    "11: axial;   g_z g_5\n",
    "7: axial;  -g_t g_5\n",
    "9: tensor;  g_x g_t\n",
    "10: tensor;  g_y g_t\n",
    "12: tensor;  g_z g_t\n",
    "3: tensor;  g_x g_y\n",
    "6: tensor;  g_y g_z\n",
    "5: tensor;  g_x g_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tsep': '12', 'quark': 'D', 'l': '0', 'g': '0', 'src': '5.0', 'snk': '5.0', 'qz': '+0', 'qy': '+0', 'qx': '+0'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "string = (\n",
    "    \"3pt_tsep12/NUCL_D_MIXED_NONREL_l0_g0/src5.0_snk5.0/qz+0_qy+0_qx+0/C13.b_5682/AMA\"\n",
    ")\n",
    "\n",
    "patterns = [\n",
    "    \"3pt\",\n",
    "    \"_tsep(?P<tsep>[0-9]|[0-9]+)\",  # must match `_tsep` and stores the following numbers (any length)\n",
    "    \"/NUCL_(?P<quark>U|D)\",  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\",  # Not sure if this changes. Not stored for now\n",
    "    \"_l(?P<l>[0-9]+)\",  # action parameters?\n",
    "    \"_g(?P<g>[0-15]+)\",\n",
    "    \"/src(?P<src>[0-9\\.]+)\",  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\",  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"/qz(?P<qz>[\\+\\-0-9]+)\", \n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\", \n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\", \n",
    "    \n",
    "]\n",
    "\n",
    "for n in range(len(patterns)):\n",
    "    pattern = \"\".join(patterns[:n+1])\n",
    "    match = re.match(pattern, string)\n",
    "    if not match:\n",
    "        print(pattern)\n",
    "        break\n",
    "\n",
    "if match:\n",
    "    print(match.groupdict())\n",
    "# 3pt_tsep8/NUCL_U_MIXED_NONREL_l0_g9/src5.0_snk5.0/qz-3_qy+0_qx+1/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A1_A1/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A1_A1_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A3_P_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A4_A4_px3_py1_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A4_P/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A4_P_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_vector_T12_T12_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current_SP/src5.0_snk5.0/ext_vector_V2_V2_px1_py1_pz1/C13.b_5682/AMA\n",
    "# 2pt/pion/src5.0_snk5.0/pion_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/pion_SP/src5.0_snk5.0/pion_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/proton/src5.0_snk5.0/proton_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/proton_SP/src5.0_snk5.0/proton_px1_py0_pz0/C13.b_5682/AMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_baryon_tag(datatag):\n",
    "    ''' Given a datatag, return dict with keys to pass into fitter  '''\n",
    "    datatag_split = datatag.split('/')\n",
    "    corr_type     = datatag_split[0]\n",
    "    tsep          = int(corr_type.split('_tsep')[1])\n",
    "    buffer        =  datatag_split[1]\n",
    "    channel       = buffer.split('_')[0]\n",
    "    quark_ins       = buffer.split('_')[1]\n",
    "    spin_proj       = buffer.split('_')[2]\n",
    "    quark_sep       = buffer.split('_')[3]\n",
    "    gamma           = buffer.split('_')[4] #gamma matrix of quark bilinear operator in the CHROMA convention , value accessed via dict\n",
    "    src_snk_sep     = datatag_split[2]\n",
    "    mom         = datatag_split[3]\n",
    "    mom0       = mom.split('_')[0]\n",
    "    mom1       = mom.split('_')[1]\n",
    "    mom2       = mom.split('_')[2]\n",
    "    momentum        = (mom0,mom1,mom2)\n",
    "    config   = datatag_split[4]\n",
    "\n",
    "    data_dict = dict()\n",
    "    data_dict['corr_type']   = corr_type\n",
    "    data_dict['tsep']        = tsep\n",
    "    data_dict['buffer']      = buffer\n",
    "    data_dict['channel']     = channel\n",
    "    data_dict['quark_ins']   = quark_ins\n",
    "    data_dict['spin_proj']   = spin_proj\n",
    "    data_dict['quark_sep']   = quark_sep\n",
    "    data_dict['gamma']       = gamma\n",
    "    data_dict['src_snk_sep'] = src_snk_sep\n",
    "    data_dict['mom']         = momentum\n",
    "    data_dict['config']      = config\n",
    "    return data_dict\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corr_type': '3pt_tsep12',\n",
       " 'tsep': 12,\n",
       " 'buffer': 'NUCL_D_MIXED_NONREL_l0_g0',\n",
       " 'channel': 'NUCL',\n",
       " 'quark_ins': 'D',\n",
       " 'spin_proj': 'MIXED',\n",
       " 'quark_sep': 'NONREL',\n",
       " 'gamma': 'l0',\n",
       " 'src_snk_sep': 'src5.0_snk5.0',\n",
       " 'mom': ('qz+0', 'qy+0', 'qx+0'),\n",
       " 'config': 'C13.b_5682'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parse_baryon_tag(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_2pt_spec(params,dsets,h5_file =None,collect=False):\n",
    "    params = dict(params)\n",
    "    params['buffer'] = pion \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"tsep\", \"quark\", \"l\", \"g\", \"src\", \"snk\",\"qz\",\"qy\",\"qx\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-16 20:27:20,527|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_5682.ama.h5`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tsep</th>\n",
       "      <th>g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tsep</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tsep   g\n",
       "tsep   NaN NaN\n",
       "g      NaN NaN"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames = []\n",
    "\n",
    "with h5py.File(file, \"r\") as h5f:\n",
    "    dsets = get_dsets(h5f)\n",
    "    # print(dsets)\n",
    "    for key, dset in dsets.items():\n",
    "        match = re.search(pattern, string)\n",
    "        if match:\n",
    "            info = match.groupdict()\n",
    "            # print(info)\n",
    "#             corr = info.pop(\"tsep\")\n",
    "\n",
    "            quark = info.pop(\"quark\")\n",
    "            # print(quark)\n",
    "            info[\"quark\"] = quark[0]\n",
    "# #             # info[\"parity\"] = -1 if len(nucleon_parity) == 2 else 1\n",
    "            \n",
    "            gamma = info.pop(\"g\")\n",
    "            if gamma in [\"g1\",\"g2\",\"g4\",\"g8\"]:\n",
    "                info[\"gamma\"] = \"vector\"\n",
    "            elif gamma in [\"g0\"]:\n",
    "                info[\"gamma\"] = \"scalar\"\n",
    "            elif gamma in [\"g5\"]:\n",
    "                info[\"gamma\"] = \"pseudoscalar\"\n",
    "            elif gamma in [\"g14\",\"g13\",\"g11\",\"g7\"]:\n",
    "                info[\"gamma\"] = \"axial\"\n",
    "            elif gamma in [\"g14\",\"g13\",\"g11\",\"g7\"]:\n",
    "                info[\"gamma\"] = \"axial\"\n",
    "            elif gamma in [\"g9\",\"g10\",\"g12\",\"g3\",\"g6\",\"g5\"]:\n",
    "                info[\"gamma\"] = \"tensor\"\n",
    "\n",
    "            # current_key = key.replace(\"g\", \"\")\n",
    "            curr_dset = h5f[key]\n",
    "\n",
    "            cfgs = dset[:]\n",
    "            corr = (\n",
    "                curr_dset[()].real \n",
    "                # if info[\"current\"] in [\"V4\"] else curr_dset[()].imag\n",
    "            )\n",
    "            # print(corr.shape[-1])\n",
    "            ts = range(corr.shape[-1])\n",
    "            # print(ts)\n",
    "            tmp_df = (\n",
    "                pd.DataFrame(index=cfgs, columns=ts, data=corr)\n",
    "                .unstack()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"level_0\": \"tsep\", \"level_1\": \"cfg\", 0: \"corr\"})\n",
    "            )\n",
    "            # data_frames = {}\n",
    "            ydict = {}\n",
    "            for key, val in info.items():\n",
    "                tmp_df[key] = val\n",
    "            data_frames.append(tmp_df.astype({\"tsep\": int}))\n",
    "            # print(data_frames)\n",
    "\n",
    "\n",
    "df = pd.concat(\n",
    "    data_frames, \n",
    "    ignore_index=True, \n",
    ").reindex(columns, axis=1).sort_values(columns).reset_index(drop=True)\n",
    "\n",
    "# df.head()\n",
    "# print(df.keys())\n",
    "# for 'tsep' in df.keys():\n",
    "#     if not isinstance(tsep, int):\n",
    "#                 raise TypeError(\"t_sink keys must be integers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          12\n",
      "1          12\n",
      "2          12\n",
      "3          12\n",
      "4          12\n",
      "           ..\n",
      "3729211    12\n",
      "3729212    12\n",
      "3729213    12\n",
      "3729214    12\n",
      "3729215    12\n",
      "Name: tsep, Length: 3729216, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import corr_functions as cf \n",
    "print(df.tsep)\n",
    "ydict = {tag: val for tag, val in df.items() if isinstance(tag, int)}\n",
    "ydict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistical average ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_data(arg):\n",
    "    corr_avg = gvar.dataset.avg_data(\n",
    "        arg.pivot(index=\"cfg\", columns=\"t\", values=\"corr\").values\n",
    "    )\n",
    "    return pd.Series(corr_avg)\n",
    "\n",
    "\n",
    "group = isospin_spin_parity_avg_df.groupby([\"nucleon\", \"current\", \"tsep\"])\n",
    "corr_df = (\n",
    "    group.apply(avg_data)\n",
    "    .reset_index(level=-1)\n",
    "    .rename(columns={\"level_3\": \"t\", 0: \"corr\"})\n",
    "    .reset_index()\n",
    "    .set_index([\"nucleon\", \"current\", \"tsep\", \"t\"])\n",
    ")\n",
    "\n",
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum average ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_avg(h5_data,state,mom_lst,weights=False):\n",
    "    '''\n",
    "    perform a momentum average of a state from an open h5 file\n",
    "    data file is assumed to be of shape [Nt,Nz,Ny,Nx,[re,im]]\n",
    "    data_mom = h5_data[state][:,pz,py,px]\n",
    "    '''\n",
    "    d_lst = []\n",
    "    w = []\n",
    "    for mom in mom_lst:\n",
    "        px,py,pz = mom['momentum']\n",
    "        w.append(mom['weight'])\n",
    "        #print(state)\n",
    "        d_lst.append(h5_data[state][:,pz,py,px])\n",
    "    d_lst = np.array(d_lst)\n",
    "    w = np.array(w)\n",
    "    if weights:\n",
    "        for wi,we in enumerate(w):\n",
    "            d_lst[wi] = we*d_lst[wi]\n",
    "        d_avg = np.sum(d_lst,axis=0) / np.sum(w)\n",
    "    else:\n",
    "        d_avg = np.mean(d_lst,axis=0)\n",
    "    return d_avg\n",
    "# mom_avg('/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_5178.ama.h5', state, mom_lst)\n",
    "\n",
    "mom_lst = []\n",
    "for px in range(-2,3):\n",
    "    for py in range(-2,3):\n",
    "        for pz in range(-2,3):\n",
    "            if px**2 + py**2 + pz**2 <= 5:\n",
    "                mom_lst.append('pz'+str(pz)+'_py'+str(py)+'_px'+str(px))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gvar as gv\n",
    "import re \n",
    "# import pandas as pd \n",
    "import sys\n",
    "import copy\n",
    "import tables as h5\n",
    "import h5py\n",
    "import os \n",
    "import time\n",
    "import collections\n",
    "# sys.path.insert(0,'home/gbradley/nucleon_elastic_FF')\n",
    "# sys.path.insert(0, '/Users/grantdb/nucleon_elastic_FF')\n",
    "sys.path.insert(0,'/Users/grantdb/lqcd/c51_corr_analysis')\n",
    "from h5io import get_dsets \n",
    "from parsing import parse_t_info, parse_file_info \n",
    "\n",
    "from concat_ import concatenate,concat_dsets\n",
    "# from nucleon_elastic_ff.data.scripts.concat import concat_dsets\n",
    "# from src.concat import concat_dsets\n",
    "from utils import group_files,parse_dset_address\n",
    "from average_spec import dset_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tsep': 10}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_ = (\n",
    "    '3pt_tsep10/NUCL_D_MIXED_NONREL_l0_g0/src5.0_snk5.0/qz+0_qy+0_qx+0/C13.b_5682/AMA'\n",
    ")\n",
    "pattern = {\"3pt\": '3pt',\n",
    "    \"_tsep(?P<tsep>[0-9][0-9]+)\":'',  # must match `_tsep` and stores the following numbers (any length)\n",
    "    \"/NUCL_(?P<quark>U|D)\":'',  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\":'',  # Not sure if this changes. Not stored for now\n",
    "    \"_l(?P<l>[0-9]+)\": '',  # action parameters?\n",
    "    \"_g(?P<g>[0-15]+)\":'',\n",
    "    \"src(?P<src>[0-9\\.]+)\\/\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\\/\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"qz(?P<qz>[\\+\\-0-9]+)\\/\":'', \n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\\/\":'', \n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\\/\":'',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''}\n",
    "\n",
    "# parse_dset_address(string,dset_replace_patterns=pattern)\n",
    "def get_tsep(string):\n",
    "    result = {}\n",
    "    match = re.search(r\"_tsep(?P<tsep>[0-9][0-9]+)\", string)\n",
    "    if match:\n",
    "            for key, val in match.groupdict().items():\n",
    "                result[key] = int(val)\n",
    "    return result\n",
    "get_tsep(string_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1816153862.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/51/q64yvfmn7fsfsg6cw1l6w8_00000kq/T/ipykernel_72942/1816153862.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    ):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def slice_file(\n",
    "    file_address_in: str,\n",
    "    file_address_out: str,\n",
    "    overwrite: bool = False,\n",
    "    tslice_fact: Optional[float] = None,\n",
    "    dset_patterns: List[str] = (\"local_current\",),\n",
    "    boundary_sign_flip: bool = False,\n",
    "):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3pt/AMA {'tsep': '21', 'quark': 'D', 'l': '0', 'g': '0', 'src': '10.0', 'snk': '10.0', 'qz': '+0', 'qy': '+0', 'qx': '+0', 'cfg': 'E7.a_1716'}\n"
     ]
    }
   ],
   "source": [
    "#h5fname = '/home/gbradley/c51_corr_analysis/tests/data/a09m135_s_avg_srcs0-15.h5'\n",
    "h5fname = '/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_4002.ama.h5'\n",
    "\n",
    "stringg='2pt/proton/src10.0_snk10.0/proton/E7.a_1716/AMA'\n",
    "# string='2pt/pion/src10.0_snk10.0/pion/E7.0_1716/AMA'\n",
    "dset_replace_patterns = {}\n",
    "dset_replace_patterns['pion'] = {\n",
    "    '2pt' : '2pt',\n",
    "    '(?P<corr>pion)':'pion',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "dset_replace_patterns['pion_SP'] = {\n",
    "    '2pt' : '2pt',\n",
    "    #'(?P<corr>pion|pion_SP|proton|proton_SP)':'corr',\n",
    "    '(?P<corr>pion_SP)':'pion_SP',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "dset_replace_patterns['proton'] = {\n",
    "    '2pt' : '2pt',\n",
    "    #'(?P<corr>pion|pion_SP|proton|proton_SP)':'corr',\n",
    "    '(?P<corr>proton)':'proton',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "dset_replace_patterns['proton_SP'] = {\n",
    "    '2pt' : '2pt',\n",
    "    #'(?P<corr>pion|pion_SP|proton|proton_SP)':'corr',\n",
    "    '(?P<corr>proton_SP)':'proton_SP',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "    } # note the trailing /\n",
    "\n",
    "dset_replace_patterns['3pt'] = {\n",
    "    '3pt_tsep(?P<tsep>[0-9][0-9]+)' : '3pt',\n",
    "    \"/NUCL_(?P<quark>U|D)\" : '',  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\" : '',  # Not sure if this changes. Not stored for now\n",
    "    \"_l(?P<l>[0-9]+)\":'',  # action parameters?\n",
    "    \"_g(?P<g>[0-15]+)\":'',\n",
    "    \"/src(?P<src>[0-9\\.]+)\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\":'',  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"/qz(?P<qz>[\\+\\-0-9]+)\":'', \n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\":'', \n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\":'',\n",
    "    '(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''\n",
    "}\n",
    "string_ = '3pt_tsep21/NUCL_D_MIXED_NONREL_l0_g0/src10.0_snk10.0/qz+0_qy+0_qx+0/E7.a_1716/AMA'\n",
    "out_grp,meta_info = parse_dset_address(string_,dset_replace_patterns=dset_replace_patterns['3pt'])\n",
    "print(out_grp,meta_info)\n",
    "# for keys in meta_info.keys():\n",
    "    \n",
    "# for key in dset_parsed.keys():\n",
    "# out_grp,meta_info = parse_dset_address(stringg,dset_replace_patterns=dset_replace_patterns['proton'])\n",
    "# from src.parsing import parse_file_info\n",
    "# parse_file_info(string_)\n",
    "# print(out_grp,meta_info)\n",
    "# dset_replace_patterns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_1000.ama.h5',\n",
       "       '/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_1004.ama.h5',\n",
       "       '/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_1008.ama.h5',\n",
       "       ...,\n",
       "       '/home/gbradley/c51_corr_analysis/tests/data/E7/E7-c_988.ama.h5',\n",
       "       '/home/gbradley/c51_corr_analysis/tests/data/E7/E7-c_992.ama.h5',\n",
       "       '/home/gbradley/c51_corr_analysis/tests/data/E7/E7-c_996.ama.h5'],\n",
       "      dtype='<U63')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens = 'E7'\n",
    "data_dir = '/home/gbradley/c51_corr_analysis/tests/data/E7/' #all configurations\n",
    "#data_dir = '/Users/grantdb/lqcd/c51_corr_analysis/tests/data/E7/'\n",
    "\n",
    "dirs = os.listdir( data_dir )\n",
    "cnf_abbr = [files.split(\".ama.h5\")[0] for files in dirs]\n",
    "cnf_abbr = [cnf.replace('-','.') for cnf in cnf_abbr]\n",
    "# cnf_abbr_ascend = {}\n",
    "cnf_abbr_ascend = [cnf_.split('_')[1] for cnf_ in cnf_abbr]\n",
    "cfg_abbr_sorted = np.sort(cnf_abbr_ascend,axis=None)\n",
    "with open(\"cfg.txt\",\"a\") as f: \n",
    "\n",
    "    print(cfg_abbr_sorted.astype(int).tolist(),file=f)\n",
    "# embed()\n",
    "data_file_list = list()\n",
    "for dirpath,_,filenames in os.walk(data_dir):\n",
    "    for f in filenames:\n",
    "        data_file_list.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "sorted_files = np.sort(data_file_list)\n",
    "sorted_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.61213983e-12, -4.86947479e-15],\n",
       "       [ 1.36353272e-12,  1.79628180e-14],\n",
       "       [ 7.49015830e-13,  9.07777055e-15],\n",
       "       [ 4.84999943e-13,  9.86840742e-17],\n",
       "       [ 3.16559633e-13,  3.69761673e-15],\n",
       "       [ 2.18787559e-13,  3.84348829e-15],\n",
       "       [ 1.50027184e-13,  6.14763143e-15],\n",
       "       [ 1.05548559e-13,  3.73334806e-15],\n",
       "       [ 7.73647492e-14,  2.99391411e-15],\n",
       "       [ 5.81585308e-14,  6.02869611e-15],\n",
       "       [ 4.22523952e-14,  4.43758061e-15],\n",
       "       [ 3.30272388e-14,  4.85967740e-15],\n",
       "       [ 2.24184224e-14,  3.97139640e-15],\n",
       "       [ 1.58846166e-14,  3.22719977e-15],\n",
       "       [ 1.08118694e-14,  3.62853507e-15],\n",
       "       [ 8.13412807e-15,  2.41446877e-15],\n",
       "       [ 6.26693055e-15,  1.84614490e-15],\n",
       "       [ 4.85448868e-15,  1.41503486e-15],\n",
       "       [ 3.99626901e-15,  1.39476841e-15],\n",
       "       [ 2.56401360e-15,  1.00926123e-15],\n",
       "       [ 1.64280740e-15,  4.34052081e-16],\n",
       "       [ 1.04611775e-15,  4.58760276e-16],\n",
       "       [ 4.29554639e-16,  2.97137111e-16],\n",
       "       [ 5.74719599e-16,  1.25345304e-16],\n",
       "       [ 3.09395762e-16,  9.52144694e-17],\n",
       "       [ 6.93170767e-17, -4.07951196e-18],\n",
       "       [-3.35582793e-17, -5.93421849e-17],\n",
       "       [ 4.57107967e-17, -1.17540747e-16],\n",
       "       [ 3.08234034e-17, -1.87315324e-16],\n",
       "       [-4.34375733e-17, -6.31330449e-17],\n",
       "       [-4.66020893e-17,  3.07738306e-17],\n",
       "       [-1.00720897e-17,  8.88699065e-18],\n",
       "       [ 3.62076938e-12, -3.51424774e-14],\n",
       "       [ 1.43342650e-12, -2.50277222e-14],\n",
       "       [ 7.75473715e-13, -2.31065213e-14],\n",
       "       [ 4.91075266e-13, -1.80769265e-14],\n",
       "       [ 3.04287552e-13, -8.88224818e-15],\n",
       "       [ 2.04616403e-13, -3.69165707e-15],\n",
       "       [ 1.48820744e-13, -3.07054744e-15],\n",
       "       [ 1.01345387e-13, -1.43291444e-15],\n",
       "       [ 6.89850265e-14, -1.52652213e-15],\n",
       "       [ 4.78146304e-14,  2.81604169e-16],\n",
       "       [ 3.41770747e-14, -5.01920231e-16],\n",
       "       [ 2.46422406e-14,  3.02896225e-17],\n",
       "       [ 1.70063501e-14,  6.68991910e-16],\n",
       "       [ 1.30300781e-14,  7.76915088e-16],\n",
       "       [ 9.73880070e-15,  4.37709195e-16],\n",
       "       [ 7.10425228e-15,  7.00019633e-16],\n",
       "       [ 5.04787208e-15,  5.15894629e-16],\n",
       "       [ 3.14698725e-15,  5.40771175e-16],\n",
       "       [ 2.40768041e-15,  6.57938940e-16],\n",
       "       [ 2.05558832e-15,  4.97445147e-16],\n",
       "       [ 1.58399865e-15,  9.94688725e-17],\n",
       "       [ 1.11771057e-15,  9.47495225e-17],\n",
       "       [ 9.75875122e-16,  7.44211622e-17],\n",
       "       [ 7.16586389e-16, -7.29487344e-17],\n",
       "       [ 7.20828735e-16, -1.99123912e-16],\n",
       "       [ 7.38754185e-16, -7.50132120e-17],\n",
       "       [ 5.85258053e-16,  2.16119494e-18],\n",
       "       [ 4.71761626e-16,  2.61038878e-17],\n",
       "       [ 3.94129419e-16,  2.45189229e-17],\n",
       "       [ 3.76932880e-16, -1.08279691e-16],\n",
       "       [ 2.44361545e-16,  1.15328505e-16],\n",
       "       [ 2.63492071e-16,  8.61277240e-17],\n",
       "       [ 3.32665216e-12, -2.57777159e-14],\n",
       "       [ 1.33151748e-12, -3.98456799e-15],\n",
       "       [ 7.23758466e-13, -8.29685892e-15],\n",
       "       [ 4.43977910e-13, -1.05649999e-15],\n",
       "       [ 3.02019893e-13, -5.22921772e-15],\n",
       "       [ 1.99271978e-13, -4.90022810e-15],\n",
       "       [ 1.44790464e-13, -4.03796431e-15],\n",
       "       [ 1.07088604e-13, -7.43636889e-15],\n",
       "       [ 6.91554477e-14, -5.15796961e-15],\n",
       "       [ 4.74374581e-14, -1.99393319e-15],\n",
       "       [ 3.36466073e-14, -1.98036082e-15],\n",
       "       [ 2.25357801e-14, -2.25412802e-15],\n",
       "       [ 1.69791797e-14, -1.85671461e-15],\n",
       "       [ 1.23844111e-14, -1.10714895e-15],\n",
       "       [ 8.37762403e-15, -1.16049584e-15],\n",
       "       [ 6.59755782e-15, -6.59908282e-16],\n",
       "       [ 5.10966580e-15, -8.22889467e-16],\n",
       "       [ 3.58792587e-15, -9.37929100e-16],\n",
       "       [ 2.15367522e-15, -3.72240372e-16],\n",
       "       [ 8.99713638e-16, -4.13843262e-16],\n",
       "       [ 4.64836937e-16, -6.78944810e-16],\n",
       "       [ 4.54442706e-16, -5.62508027e-16],\n",
       "       [ 7.96216513e-16, -7.33680516e-16],\n",
       "       [ 3.08241726e-16, -4.88101320e-16],\n",
       "       [ 1.51374620e-16, -2.94162294e-16],\n",
       "       [ 2.48139646e-18, -1.62788765e-16],\n",
       "       [ 7.07130762e-17, -6.56689452e-17],\n",
       "       [ 1.45153964e-16, -4.93855711e-17],\n",
       "       [ 6.68909859e-17, -9.91495921e-17],\n",
       "       [ 6.92470167e-17, -4.93228466e-17],\n",
       "       [ 1.37075264e-17,  6.24615936e-17],\n",
       "       [-8.39799768e-18,  5.12548175e-17],\n",
       "       [ 3.76713080e-12,  1.08269575e-15],\n",
       "       [ 1.43265908e-12, -2.78707269e-15],\n",
       "       [ 7.16171548e-13, -3.23728020e-15],\n",
       "       [ 4.44477161e-13,  6.43142833e-16],\n",
       "       [ 2.98270726e-13,  6.91682044e-15],\n",
       "       [ 2.00541511e-13,  5.14597939e-15],\n",
       "       [ 1.44186162e-13,  6.77145808e-15],\n",
       "       [ 9.18824018e-14,  4.27821791e-15],\n",
       "       [ 6.63798182e-14,  5.53060252e-15],\n",
       "       [ 4.72779048e-14,  6.02911205e-15],\n",
       "       [ 3.39346249e-14,  4.52060072e-15],\n",
       "       [ 2.48100992e-14,  3.95861481e-15],\n",
       "       [ 1.95772030e-14,  3.21594544e-15],\n",
       "       [ 1.24040182e-14,  1.99616914e-15],\n",
       "       [ 8.80439815e-15,  2.41697509e-15],\n",
       "       [ 6.03900000e-15,  1.79613542e-15],\n",
       "       [ 4.17736273e-15,  1.28614528e-15],\n",
       "       [ 3.75943025e-15,  1.29527222e-15],\n",
       "       [ 2.76308358e-15,  7.62061324e-16],\n",
       "       [ 2.36573740e-15,  2.23111137e-16],\n",
       "       [ 1.43017897e-15,  1.20906495e-16],\n",
       "       [ 1.17632105e-15,  9.86209310e-18],\n",
       "       [ 9.35435420e-16,  7.50110477e-17],\n",
       "       [ 8.64225082e-16,  3.18877614e-17],\n",
       "       [ 6.39204713e-16, -6.04770451e-17],\n",
       "       [ 4.72848444e-16,  3.90961306e-17],\n",
       "       [ 2.58002822e-16, -2.46818969e-17],\n",
       "       [ 1.79662278e-16, -1.29333833e-16],\n",
       "       [ 2.29495403e-16, -1.26299854e-16],\n",
       "       [ 1.48090139e-16, -1.26861967e-16],\n",
       "       [ 1.71153792e-16, -1.04966892e-16],\n",
       "       [ 1.39086108e-16, -8.96960278e-17]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h5f = h5py.File(sorted_files[0],'r')\n",
    "h5f = h5py.File('proton.h5','r')\n",
    "# line = next(h5f)\n",
    "# h5f = h5py.File('pion.h5','r')\n",
    "string = '2pt/proton/src10.0_snk10.0/proton/AMA'\n",
    "ifil = h5f[string][:]\n",
    "print(len(ifil))\n",
    "t,real,imag = [],[],[]\n",
    "line = np.nditer(ifil[()])\n",
    "# for x in line:\n",
    "#     print(x)\n",
    "import pandas as pd \n",
    "corrs = pd.DataFrame(ifil)\n",
    "corrs.columns\n",
    "corrs_out = corrs.to_numpy()\n",
    "corrs_out\n",
    "# data = {}\n",
    "# data['real'] = corrs_out['re'].values()\n",
    "# data['t']   = corrs_out['re'].keys()\n",
    "# data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(corrs_out['re'].keys())\n",
    "# data['t'] = corrs.index()\n",
    "# data['real'] = corrs.values['re']\n",
    "# data\n",
    "# arr= corrs.to_numpy()\n",
    "# _, nt = arr.shape\n",
    "# t = np.arange(nt)\n",
    "# front = arr[:, :nt // 2 + 1]\n",
    "# back = arr[:, (nt - t) % nt][:, :nt // 2 + 1]\n",
    "# new_arr = np.mean([front, back], axis=0)\n",
    "# new_arr\n",
    "# with open(sorted_files[0],'r') as ifile:\n",
    "#     for line in ifile:\n",
    "#         print(line)\n",
    "# # line = next(ifile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object at 0x7fc479915680>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-339-32ac8d27e800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mcorr_imag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcorr_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mcorr_imag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mcorr_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "from fitter.prepare_data_lanl import *\n",
    "blocked = block_data(new_arr,bl=1)\n",
    "dsum = np.sum(blocked,axis=1)\n",
    "# print(dsum)\n",
    "\n",
    "# print(blocked.shape)\n",
    "binned_cov = gv.evalcov(gv.dataset.avg_data(blocked))\n",
    "error = np.diag(np.sqrt(np.diag(binned_cov)))\n",
    "# print(error)\n",
    "# print(binned_cov)\n",
    "to_arrays = np.hsplit(blocked,1)\n",
    "gv.dataset.avg_data(to_arrays)\n",
    "no_shrink= gv.evalcorr(gv.dataset.avg_data(blocked))\n",
    "# print(no_shrink)\n",
    "\n",
    "# covariance_out = {}\n",
    "covariance_out = np.matmul(error,np.matmul(no_shrink,error))\n",
    "# print(covariance_out,\"c\")\n",
    "\n",
    "mean = gv.mean(gv.dataset.avg_data(blocked))\n",
    "data_iter = gv.bootstrap_iter(blocked)\n",
    "print(data_iter)\n",
    "\n",
    "cov = covariance_out\n",
    "# print(mean,\"mean\")\n",
    "# print(gv.gvar(mean,cov))\n",
    "\n",
    "# print(shrunk,\"sh\")\n",
    "# print(gv.gvar(mean,cov))\n",
    "# print(mean)\n",
    "corr_real = []\n",
    "corr_imag = []\n",
    "for i in range(len(mean)):\n",
    "    corr_real.append(mean[i][0])\n",
    "    corr_imag.append(mean[i][1])\n",
    "corr_out = {}\n",
    "# print(np.array(corr_real))\n",
    "corr_out['real']= np.array(corr_real)\n",
    "corr_out['imag'] = np.array(corr_imag)\n",
    "# (data[2:] + data[:-2]) / (2.0 * data[1:-1])\n",
    "proton = cf.C_2pt('real',corr_out['real'],skip_fastfit=False)\n",
    "print(proton.avg(),\"avg\")\n",
    "\n",
    "def restrict_real(arr):\n",
    "    mean = gv.mean(arr)\n",
    "    mask = np.isfinite(mean)\\\n",
    "        & ~np.isnan(mean)\n",
    "        # & np.isfinite(sdev)\\\n",
    "        \n",
    "        # & ~np.isnan(sdev)\n",
    "    return arr[mask]\n",
    "import plotting as plot\n",
    "plot.plot_correlators(corr_out)\n",
    "\n",
    "# restrict_real(proton.meff())\n",
    "# proton.avg()\n",
    "# mean\n",
    "# binned_cov = gv.evalcov(gv.dataset.avg_data(corrs))\n",
    "# binned_cov\n",
    "# gv.evalcorr(gv.dataset.avg_data(corrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_datablock(ifile):\n",
    "    \"\"\"\n",
    "    Parses a correlator data block into lists of t, Re(C), Im(C).\n",
    "    Args:\n",
    "        ifile:\n",
    "    Returns:\n",
    "        t, real, imag: three lists with the data\n",
    "    Notes:\n",
    "    The data block is assumed to consist of three columns like the following:\n",
    "    0 3.103021e-06 0.000000e+00\n",
    "    1 8.273227e-07 0.000000e+00\n",
    "    ...\n",
    "    ENDPROP\n",
    "    The datablock ends with the flag \"ENDPROP\".\n",
    "    \"\"\"\n",
    "    # Use regex to be picky about what constitutes data and to fail\n",
    "    # early and noisily if something unexpected appears\n",
    "    scientific = r\"(-?(?:0|[1-9]\\d*)(?:\\.\\d*)?(?:[eE][+\\-]?\\d+)?)\"\n",
    "    datum = re.compile(r\"^(\\d+)\" + f\" {scientific} {scientific}$\")\n",
    "    t, real, imag = [], [], []\n",
    "    data_block = True\n",
    "    while data_block:\n",
    "        line = next(ifile)\n",
    "        match = re.match(datum, line)\n",
    "        if match:\n",
    "            tokens = match.groups() # t, real, imag\n",
    "            t.append(tokens[0])\n",
    "            real.append(tokens[1])\n",
    "            imag.append(tokens[2])\n",
    "        elif \"ENDPROP\" in line:\n",
    "            data_block = False\n",
    "        else:\n",
    "            LOGGER.error(\"ERROR: Unrecognized line in data block %s\", line)\n",
    "            raise ValueError(f\"Unrecognized line in data block, {line}\")\n",
    "    return t, real, imag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'File' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-7d8b6b9ba4ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparse_datablock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-9eff271a7281>\u001b[0m in \u001b[0;36mparse_datablock\u001b[0;34m(ifile)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdata_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mdata_block\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'File' object is not an iterator"
     ]
    }
   ],
   "source": [
    "parse_datablock(h5f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-05 12:56:24,803|nucleon_elastic_ff@INFO] Starting averaging over `2` files with hdf5 group/dset substitutions\n",
      "[2022-09-05 12:56:24,804|nucleon_elastic_ff@INFO] \t'2pt' = '2pt'\n",
      "[2022-09-05 12:56:24,804|nucleon_elastic_ff@INFO] \t'(?P<corr>pion)' = 'pion'\n",
      "[2022-09-05 12:56:24,805|nucleon_elastic_ff@INFO] \t'(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/' = ''\n",
      "[2022-09-05 12:56:24,805|nucleon_elastic_ff@INFO] The export file will be called `/home/gbradley/c51_corr_analysis/src/fitter/pion_avg.h5`\n",
      "[2022-09-05 12:56:24,805|nucleon_elastic_ff@INFO] Start parsing files\n",
      "[2022-09-05 12:56:24,806|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_1000.ama.h5`\n",
      "[2022-09-05 12:56:33,305|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_1004.ama.h5`\n",
      "[2022-09-05 12:56:42,262|nucleon_elastic_ff@INFO] Writing `22` dsets to `/home/gbradley/c51_corr_analysis/src/fitter/pion_avg.h5`\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/home/gbradley/c51_corr_analysis/src/fitter/pion_avg.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-8aa812c12af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mout_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pion_avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pion_avg.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdset_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pion_avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/c51_corr_analysis/src/average_spec.py\u001b[0m in \u001b[0;36mdset_avg\u001b[0;34m(files, out_file, dset_replace_patterns, overwrite, expected_dsets, fail_unexpected_dsets)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Writing `%d` dsets to `%s`\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mh5f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsets_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             LOGGER.debug(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 533\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/home/gbradley/c51_corr_analysis/src/fitter/pion_avg.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from average_spec import dset_avg\n",
    "out_file = {}\n",
    "out_file['pion_avg'] = os.path.join(os.getcwd(),\"pion_avg.h5\")\n",
    "dset_avg(sorted_files[0:2],out_file=out_file['pion_avg'],dset_replace_patterns=dset_replace_patterns['pion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-05 12:06:30,397|lanl lqcd analysis@INFO] Starting concatenating over `4` files with hdf5 group/dset substitutions\n",
      "[2022-09-05 12:06:30,398|lanl lqcd analysis@INFO] \t'2pt' = '2pt'\n",
      "[2022-09-05 12:06:30,399|lanl lqcd analysis@INFO] \t'(?P<corr>pion)' = 'pion'\n",
      "[2022-09-05 12:06:30,399|lanl lqcd analysis@INFO] \t'(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/' = ''\n",
      "[2022-09-05 12:06:30,399|lanl lqcd analysis@INFO] The export file will be called `/home/gbradley/c51_corr_analysis/src/fitter/pion.h5`\n",
      "[2022-09-05 12:06:30,400|lanl lqcd analysis@INFO] Start parsing files\n",
      "[2022-09-05 12:06:30,425|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-a_1716.ama.h5`\n",
      "[2022-09-05 12:06:39,176|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_2216.ama.h5`\n",
      "[2022-09-05 12:06:48,018|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-b_1124.ama.h5`\n",
      "[2022-09-05 12:06:56,706|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/E7/E7-0_1964.ama.h5`\n",
      "[2022-09-05 12:07:05,196|lanl lqcd analysis@INFO] Writing `22` dsets to `/home/gbradley/c51_corr_analysis/src/fitter/pion.h5`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-41d9548e8674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# for corr in dset_replace_patterns.keys():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# concat_dsets(data_file_list[0:4], out_file['proton'], dset_replace_patterns=dset_replace_patterns['proton'],overwrite=False,write_unpaired_dsets=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mconcat_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_unpaired_dsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mconcat_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset_replace_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pion_SP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_unpaired_dsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# concat_dsets(data_file_list[0:4], out_file['proton_SP'], dset_replace_patterns=dset_replace_patterns['proton_SP'],overwrite=False,write_unpaired_dsets=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/c51_corr_analysis/src/concat_.py\u001b[0m in \u001b[0;36mconcat_dsets\u001b[0;34m(files, out_file, axis, dset_replace_patterns, ignore_containers, write_unpaired_dsets, overwrite)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mdset_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "\n",
    "# data_file_list = os.path.realpath(dirs)\n",
    "\n",
    "# embed()\n",
    "# file = data_file_list[0]\n",
    "# dset_replace_patterns = {'(?P<cfg>E7.\\w\\_[0-9][0-9][0-9][0-9]+)\\/': ''}\n",
    "out_file = {}\n",
    "out_file['pion'] = os.path.join(os.getcwd(),\"pion.h5\")\n",
    "out_file['pion_SP'] = os.path.join(os.getcwd(),\"pion_SP.h5\")\n",
    "out_file['proton'] = os.path.join(os.getcwd(),\"proton.h5\")\n",
    "out_file['proton_SP'] = os.path.join(os.getcwd(),\"proton_SP.h5\")\n",
    "out_file['3pt_tsep13'] = os.path.join(os.getcwd(),\"3pt_tsep13.h5\")\n",
    "out_file['3pt_tsep15'] = os.path.join(os.getcwd(),\"3pt_tsep15.h5\")\n",
    "out_file['3pt_tsep17'] = os.path.join(os.getcwd(),\"3pt_tsep17.h5\")\n",
    "out_file['3pt_tsep19'] = os.path.join(os.getcwd(),\"3pt_tsep19.h5\")\n",
    "out_file['3pt_tsep21'] = os.path.join(os.getcwd(),\"3pt_tsep21.h5\")\n",
    "\n",
    "\n",
    "# TODO this needs to be in a loop, but not working with external module concat_dsets\n",
    "# for corr in dset_replace_patterns.keys():\n",
    "# concat_dsets(data_file_list[0:4], out_file['proton'], dset_replace_patterns=dset_replace_patterns['proton'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['pion'], dset_replace_patterns=dset_replace_patterns['pion'],overwrite=False,write_unpaired_dsets=False)\n",
    "concat_dsets(data_file_list[0:4], out_file['pion'], dset_replace_patterns=dset_replace_patterns['pion_SP'],overwrite=False,write_unpaired_dsets=True)\n",
    "# concat_dsets(data_file_list[0:4], out_file['proton_SP'], dset_replace_patterns=dset_replace_patterns['proton_SP'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep13'], dset_replace_patterns=dset_replace_patterns['3pt'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep15'], dset_replace_patterns=dset_replace_patterns['3pt_tsep15'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep17'], dset_replace_patterns=dset_replace_patterns['3pt_tsep17'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep19'], dset_replace_patterns=dset_replace_patterns['3pt_tsep19'],overwrite=False,write_unpaired_dsets=True)\n",
    "concat_dsets(data_file_list[0:4], out_file['3pt_tsep21'], dset_replace_patterns=dset_replace_patterns['3pt_tsep21'],overwrite=False,write_unpaired_dsets=True)\n",
    "\n",
    "# streams = {\n",
    "#     'E7' : ['0','a','b','c']\n",
    "# }\n",
    "# for i_s, s in enumerate(streams[ens]):\n",
    "#     f_in = h5.open_file(ens+'_'+s+'/'+data_dir+'/avg/'+ens+'_'+s+'_avg_srcs'+srcs[ens]+'.h5')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-05 15:28:34,931|lqcd correlator analysis@INFO] Locating all dsets of h5 file `pion.h5`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['real', 'imag'])\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('pion.h5','r')\n",
    "string = '2pt/proton/src10.0_snk10.0/proton/E7.a_1716/AMA'\n",
    "# h5f = h5py.File('example_data.hdf5','r')\n",
    "dsets = get_dsets(h5f)\n",
    "# print(dsets)\n",
    "for dset in dsets:\n",
    "    arr = h5f[dset][:]\n",
    "# print(corr)\n",
    "\n",
    "# corr_ = np.array(corr)\n",
    "corr_real = []\n",
    "corr_imag = []\n",
    "for i in range(len(arr)):\n",
    "    corr_real.append(arr[i][0])\n",
    "    corr_imag.append(arr[i][1])\n",
    "corr_out = {}\n",
    "corr_out['real']= np.array(corr_real)\n",
    "corr_out['imag'] = np.array(corr_imag)\n",
    "# test = np.column_stack((corr_out,corr_out_))\n",
    "# print(test.shape)\n",
    "# arr = corr_out['pion']\n",
    "# nt = test.shape[0]\n",
    "# t = np.arange(nt)\n",
    "# front = test[:nt // 2 + 1]\n",
    "# back = test[(nt - t) % nt][:nt // 2 + 1]\n",
    "# new_arr = np.mean([front, back], axis=0)\n",
    "# print(new_arr.shape)\n",
    "# corr_out[1:-1]\n",
    "# corr_out['pion']\n",
    "# print(gv.sdev(corr_out['pion']))\n",
    "print(corr_out.keys())\n",
    "import corr_functions as cf \n",
    "def _infer_tmax(ydata, noise_threshy):\n",
    "    \"\"\"Infer the maximum time with noise-to-signal below a threshold.\"\"\"\n",
    "    if noise_threshy is None:\n",
    "        return len(ydata) - 1\n",
    "    good = gv.sdev(ydata) / gv.mean(ydata) < noise_threshy\n",
    "    if np.all(good):\n",
    "        tmax = len(ydata) - 1\n",
    "    else:\n",
    "        tmax = np.argmin(good)\n",
    "    return tmax\n",
    "\n",
    "# _infer_tmax(corr_out['pion'],noise_threshy=0.02)\n",
    "\n",
    "\n",
    "# cf.C_2pt(tag='pion',ydata=corr_out['pion'])\n",
    "\n",
    "# # def bin(array,binsize=1):\n",
    "# #     if binsize <= 1:\n",
    "# #         return arrary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('imag',\n",
       "  'imag'): BufferDict({('imag', 'imag'): 2.82(23)e-07, ('imag', 'real'): 2.82(23)e-07, ('real', 'imag'): 2.82(23)e-07, ('real', 'real'): 2.82(23)e-07}),\n",
       " ('imag',\n",
       "  'real'): BufferDict({('imag', 'imag'): 2.82(23)e-07, ('imag', 'real'): 2.82(23)e-07, ('real', 'imag'): 2.82(23)e-07, ('real', 'real'): 2.82(23)e-07}),\n",
       " ('real',\n",
       "  'imag'): BufferDict({('imag', 'imag'): 2.82(23)e-07, ('imag', 'real'): 2.82(23)e-07, ('real', 'imag'): 2.82(23)e-07, ('real', 'real'): 2.82(23)e-07}),\n",
       " ('real',\n",
       "  'real'): BufferDict({('imag', 'imag'): 2.82(23)e-07, ('imag', 'real'): 2.82(23)e-07, ('real', 'imag'): 2.82(23)e-07, ('real', 'real'): 2.82(23)e-07})}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def compute_cov_matrix(corr_out,ordered_datatags=None,bstrap=False,inflate=1.0):\n",
    "\n",
    "    ordered_tags = sorted(corr_out.keys(), key=str)\n",
    "    \n",
    "    sizes = [corr_out[datatag].shape[0] for datatag in ordered_tags]\n",
    "\n",
    "        # sizes = [data[tag].shape[1] for tag in ordered_tags]\n",
    "    total_size = np.sum(sizes)\n",
    "    \n",
    "    binned_data = {datatag: corr_out[datatag] for datatag in ordered_tags}\n",
    "    binned_cov = gv.evalcov(gv.dataset.avg_data(binned_data, bstrap=bstrap))\n",
    "    err = {}\n",
    "    for key_pair in binned_cov:\n",
    "        key1, key2 = key_pair\n",
    "        if key1 == key2:\n",
    "            err[key1] =\\\n",
    "                inflate * np.diag(np.sqrt(np.diag(binned_cov[key_pair])))\n",
    "    # print(binned_cov)\n",
    "    no_shrink_data = gv.evalcorr(gv.dataset.avg_data({datatag: binned_data[datatag] for datatag in ordered_tags}))\n",
    "    samples_to_arrays = np.hstack([corr_out[datatag] for datatag in ordered_tags])\n",
    "        # if total_size == len(ordered_tags):\n",
    "        #     # edge case: single datum per sample\n",
    "        #     samples = samples.reshape(-1, len(ordered_tags))\n",
    "    # print(samples_to_arrays)\n",
    "    final_cov = {}\n",
    "    for key_l, key_r in no_shrink_data:\n",
    "        # err x corr x err\n",
    "        final_cov[(key_l, key_r)] = samples_to_arrays[:] #np.matmul(err[key_l],np.matmul(samples_to_arrays[(key_l, key_r)],err[key_r])\n",
    "                                        \n",
    "    return final_cov\n",
    "ordered_tags = sorted(corr_out.keys(), key=str)\n",
    "samples_to_arrays = np.hstack([corr_out[datatag] for datatag in ordered_tags])\n",
    "samples = [[i] for i in samples_to_arrays]\n",
    "# print(samples,'sam') \n",
    "# print(samples_to_arrays,\"sa\")\n",
    "cov = compute_cov_matrix(corr_out)\n",
    "# print(cov,\"cov\")\n",
    "mean = gv.mean(gv.dataset.avg_data(corr_out))\n",
    "# gv.gvar(mean,cov)\n",
    "ds = {key: gv.dataset.avg_data(cov) for key, val in cov.items()}\n",
    "ds\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_mass(data):\n",
    "        \"\"\"\n",
    "        Computes the effective mass analytically using the following formula\n",
    "        \n",
    "        meff = ArcCosh( (C(t+1)+ C(t-1)) / C(t) )\n",
    "        This method correctly accounts for contributions both from forward- and\n",
    "        backward-propagating states. \n",
    "        \"\"\"\n",
    "        cosh_m = (data[2:] + data[:-2]) / (2.0 * data[1:-1])\n",
    "        meff = np.zeros(len(cosh_m), dtype=gv._gvarcore.GVar)\n",
    "        # The domain of arccosh is [1, Infinity).\n",
    "        # Set entries outside of the domain to nans.\n",
    "        domain = (cosh_m > 1)\n",
    "        meff[domain] = np.arccosh(cosh_m[domain])\n",
    "        meff[~domain] = gv.gvar(np.nan)\n",
    "        return meff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BufferDict({('pion', 'pion'): array([[1.14581642e-15]])})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# effective_mass(corr_out)v.mean(corr_out)\n",
    "#def build_dataset():\n",
    "mean = gv.mean(gv.dataset.avg_data(corr_out))\n",
    "binned = {tag:corr_out[tag] for tag in ordered_tags}\n",
    "binned_covariance = gv.evalcov(gv.dataset.avg_data(binned))\n",
    "binned_covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-190f0e16a7a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorr_functions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc2_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_2pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pion'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/c51_corr_analysis/src/fitter/corr_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tag, ydata, noise_threshy, skip_fastfit, **time_kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mtdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtime_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_tmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_threshy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Estimate the ground-state energy and amplitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskip_fastfit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/c51_corr_analysis/src/fitter/corr_functions.py\u001b[0m in \u001b[0;36m_infer_tmax\u001b[0;34m(ydata, noise_threshy)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnoise_threshy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mgood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnoise_threshy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_utilities.pyx\u001b[0m in \u001b[0;36mgvar._utilities.sdev\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_utilities.pyx\u001b[0m in \u001b[0;36mgvar._utilities.var\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division"
     ]
    }
   ],
   "source": [
    "import corr_functions as cf \n",
    "data_ = corr_out.pop('pion')\n",
    "c2_src = cf.C_2pt('pion',data_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corr in ['proton']:\n",
    "    for parity in ['','_SP']:\n",
    "        print(corr,parity)\n",
    "        for i_s,s in enumerate(streams[ens]):\n",
    "            f_in = h5.open_file(ens+'_'+s+'/'+data_dir+'/avg/'+ens+'_'+s+'_avg_srcs'+srcs[ens]+'.h5')\n",
    "            if s == streams[ens][0]:\n",
    "                su = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_up').read()\n",
    "                sd = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_dn').read()\n",
    "                cs = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/cfgs_srcs').read()\n",
    "            else:\n",
    "                tmp_su = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_up').read()\n",
    "                tmp_sd = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/spin_dn').read()\n",
    "                tmp_cs = f_in.get_node('/'+val[ens]+'/spec/'+spec[ens]+'/'+corr+parity+'/px0_py0_pz0/cfgs_srcs').read()\n",
    "                tmp_cs[:,0] += i_s * cs_offset[ens]\n",
    "                su = np.concatenate((su,tmp_su),axis=0)\n",
    "                sd = np.concatenate((sd,tmp_sd),axis=0)\n",
    "                cs = np.concatenate((cs,tmp_cs),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tsep': '10', 'quark': 'D', 'l': '0', 'g': '0', 'src': '5.0', 'snk': '5.0', 'qz': '+0', 'qy': '+0', 'qx': '+2'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "patterns = [\n",
    "    \"3pt\",\n",
    "    \"_tsep(?P<tsep>[0-9]|[0-9]+)\",  # must match `_tsep` and stores the following numbers (any length)\n",
    "    \"/NUCL_(?P<quark>U|D)\",  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\",  # Not sure if this changes. Not stored for now\n",
    "    \"_l(?P<l>[0-9]+)\",  # action parameters?\n",
    "    \"_g(?P<g>[0-15]+)\",\n",
    "    \"/src(?P<src>[0-9\\.]+)\",  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\",  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"/qz(?P<qz>[\\+\\-0-9]+)\", \n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\", \n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\", \n",
    "    \n",
    "]\n",
    "for n in range(len(patterns)):\n",
    "    pattern = \"\".join(patterns[:n+1])\n",
    "    match = re.match(pattern, string)\n",
    "    if not match:\n",
    "        print(pattern)\n",
    "        break\n",
    "\n",
    "if match:\n",
    "    print(match.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = [\"nucleon\", \"current\", \"tsep\", \"cfg\", \"t\", \"isospin\", \"parity\", \"spin\", \"corr\"]\n",
    "columns = [\"tsep\", \"quark\", \"l\", \"g\", \"src\", \"snk\",\"qz\",\"qy\",\"qx\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-24 15:48:53,566|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_4002.ama.h5`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tsep</th>\n",
       "      <th>quark</th>\n",
       "      <th>l</th>\n",
       "      <th>g</th>\n",
       "      <th>src</th>\n",
       "      <th>snk</th>\n",
       "      <th>qz</th>\n",
       "      <th>qy</th>\n",
       "      <th>qx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "      <td>+0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tsep quark  l  g  src  snk  qz  qy  qx\n",
       "0     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "1     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "2     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "3     8     D  0  0  5.0  5.0  +0  +0  +0\n",
       "4     8     D  0  0  5.0  5.0  +0  +0  +0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames = []\n",
    "\n",
    "with h5py.File(h5fname, \"r\") as h5f:\n",
    "    dsets = get_dsets(h5f)\n",
    "    # print(dsets)\n",
    "\n",
    "    for key, dset in dsets.items():\n",
    "        match = re.search(pattern, key)\n",
    "        if match:\n",
    "            info = match.groupdict()\n",
    "            # print(info)\n",
    "\n",
    "            # nucleon_parity = info.pop(\"parity\").split(\"_\")\n",
    "            g = info.pop(\"g\").split(\"_\")\n",
    "            # print(g)\n",
    "            info[\"g\"] = g[0]\n",
    "            # info[\"nucleon\"] = nucleon_parity[0]\n",
    "            # info[\"parity\"] = -1 if len(nucleon_parity) == 2 else 1\n",
    "            \n",
    "            # isospin = info.pop(\"isospin\")\n",
    "            # info[\"isospin\"] = 1 if isospin == \"UU\" else -1            \n",
    "\n",
    "            # current_key = key.replace(\"cfgs_srcs\", \"local_curr\")\n",
    "            curr_dset = h5f[key]\n",
    "            # print(curr_dset)\n",
    "            # print(curr_dset[0])\n",
    "            # print(curr_dset[0][0])\n",
    "\n",
    "            cfgs = dset[:]\n",
    "            # print(cfgs)\n",
    "            # print(cfgs[0])\n",
    "            corr = (\n",
    "                curr_dset[:][0] if info[\"g\"] in [\"g1\",\"g2\",\"g4\",\"g8\"] else curr_dset[:][1]\n",
    "            )\n",
    "            \n",
    "#             # print(corr)\n",
    "            ts = range(len(corr))\n",
    "#             # print(ts)\n",
    "#             # ts = range(corr.shape[-1])\n",
    "\n",
    "            tmp_df = (\n",
    "                pd.DataFrame(index=cfgs, columns=ts, data=corr)\n",
    "                .unstack()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"level_0\": \"t\", \"level_1\": \"cfg\", 0: \"corr\"})\n",
    "            )\n",
    "            # print(tmp_df)\n",
    "            for key, val in info.items():\n",
    "                tmp_df[key] = val\n",
    "            data_frames.append(tmp_df.astype({\"tsep\": int}))\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat(\n",
    "    data_frames, \n",
    "    ignore_index=True, \n",
    ").reindex(columns, axis=1).sort_values(columns).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleon</th>\n",
       "      <th>current</th>\n",
       "      <th>tsep</th>\n",
       "      <th>cfg</th>\n",
       "      <th>t</th>\n",
       "      <th>isospin</th>\n",
       "      <th>parity</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.123843e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.496932e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.118381e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.362174e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.552208e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nucleon current  tsep   cfg  t  isospin  parity          corr\n",
       "0  proton      A3     3  78.0  0       -1      -1  7.123843e-10\n",
       "1  proton      A3     3  78.0  0       -1       1 -5.496932e-10\n",
       "2  proton      A3     3  78.0  0        1      -1  1.118381e-09\n",
       "3  proton      A3     3  78.0  0        1       1 -8.362174e-10\n",
       "4  proton      A3     3  78.0  1       -1      -1  9.552208e-10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spin_avg_df = df.groupby(\n",
    "    [\"nucleon\", \"current\", \"tsep\", \"cfg\", \"t\", \"isospin\", \"parity\"], as_index=False\n",
    ")[\"corr\"].mean()\n",
    "\n",
    "spin_avg_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleon</th>\n",
       "      <th>current</th>\n",
       "      <th>tsep</th>\n",
       "      <th>cfg</th>\n",
       "      <th>t</th>\n",
       "      <th>isospin</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6.310388e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.772991e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6.853185e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.990430e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-6.418973e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nucleon current  tsep   cfg  t  isospin          corr\n",
       "0  proton      A3     3  78.0  0       -1 -6.310388e-10\n",
       "1  proton      A3     3  78.0  0        1 -9.772991e-10\n",
       "2  proton      A3     3  78.0  1       -1 -6.853185e-10\n",
       "3  proton      A3     3  78.0  1        1 -5.990430e-10\n",
       "4  proton      A3     3  78.0  2       -1 -6.418973e-10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = spin_avg_df.copy()\n",
    "tmp[\"corr\"] *= tmp[\"parity\"]\n",
    "spin_parity_avg_df = tmp.groupby(\n",
    "    [\"nucleon\", \"current\", \"tsep\", \"cfg\", \"t\", \"isospin\",  ], as_index=False\n",
    ")[[\"corr\"]].mean()\n",
    "\n",
    "spin_parity_avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleon</th>\n",
       "      <th>current</th>\n",
       "      <th>tsep</th>\n",
       "      <th>cfg</th>\n",
       "      <th>t</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.462603e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.627543e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.859727e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.257450e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proton</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.371521e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nucleon current  tsep   cfg  t          corr\n",
       "0  proton      A3     3  78.0  0 -3.462603e-10\n",
       "1  proton      A3     3  78.0  1  8.627543e-11\n",
       "2  proton      A3     3  78.0  2  2.859727e-10\n",
       "3  proton      A3     3  78.0  3  4.257450e-11\n",
       "4  proton      A3     3  84.0  0  5.371521e-10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = spin_parity_avg_df.copy()\n",
    "tmp[\"corr\"] *= tmp[\"isospin\"]\n",
    "isospin_spin_parity_avg_df = (\n",
    "    tmp.groupby([\"nucleon\", \"current\", \"tsep\", \"cfg\",  \"t\"], as_index=False)[\"corr\"]\n",
    "    .sum()\n",
    ")\n",
    "isospin_spin_parity_avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_data(arg):\n",
    "    corr_avg = gv.dataset.avg_data(\n",
    "        arg.pivot(index=\"cfg\", columns=\"t\", values=\"corr\").values\n",
    "    )\n",
    "    return pd.Series(corr_avg)\n",
    "\n",
    "\n",
    "group = isospin_spin_parity_avg_df.groupby([\"nucleon\", \"current\", \"tsep\"])\n",
    "corr_df = (\n",
    "    group.apply(avg_data)\n",
    "    .reset_index(level=-1)\n",
    "    .rename(columns={\"level_3\": \"t\", 0: \"corr\"})\n",
    "    .reset_index()\n",
    "    .set_index([\"nucleon\", \"current\", \"tsep\", \"t\"])\n",
    ")\n",
    "# # print(corr_df)\n",
    "# corr_out = corr_df.to_dict(orient='tight')\n",
    "# # print(corr_out)\n",
    "# test = corr_df.loc[('proton', 'A3'),'corr']\n",
    "# test_src = \n",
    "# out = test.to_dict()\n",
    "# ydict = {tag: val for tag,val in out.items() if isinstance(tag,tuple)}\n",
    "# # print(ydict)\n",
    "# t_snk = list()\n",
    "# for item in out.keys():\n",
    "#     if item[0] not in t_snk:\n",
    "#         t_snk.append(item[0])\n",
    "# print(t_snk)\n",
    "# import fitter.corr_functions as cf \n",
    "# c3 = cf.C_3pt(tag='proton',ydata_3pt=ydict)\n",
    "# print(c3)\n",
    "# # # print(out)\n",
    "# # list(out.keys())\n",
    "# # [i[0] for i in out.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fitter.test_corr' has no attribute 'C2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-84e84db94949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_corr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fitter.test_corr' has no attribute 'C2'"
     ]
    }
   ],
   "source": [
    "\n",
    "Nstates = collections.namedtuple('NStates', ['n', 'no', 'm', 'mo'], defaults=(2, 1, 2, 1))\n",
    "def test_NPoint(tag,data,prior): #prior\n",
    "    \"\"\"Test cf.C_2pt and cf.C_3pt class.\"\"\"\n",
    "    # print(data[tag].shape)\n",
    "    nt = data[tag].shape\n",
    "    # print(corr)\n",
    "    data_ = data.pop(tag)\n",
    "    c2_src = cf.C_2pt(tag, data_)\n",
    "    \n",
    "    # print(len(c2_src.meff(avg=True)))\n",
    "    # model =get_two_point_model(c2_src)\n",
    "    # t_start = c2_src.times.tmin \n",
    "    # t_end = c2_src.times.tmax\n",
    "    # Nstates = collections.namedtuple('NStates', ['n', 'no', 'm', 'mo'], defaults=(1, 0, 0, 0))\n",
    "    nstates = Nstates(n=2, no=1)\n",
    "    # prior = priors.MesonPriorPDG(nstates, 'pi',a_fm = .09)\n",
    "    # fitter = C_2pt_Analysis(c2_src)\n",
    "    # fit = fitter.run_fit()\n",
    "\n",
    "    # fit = fitter.run_fit()\n",
    "\n",
    "    # c2.__setitem__\n",
    "    # c2_src[0] = 1.0\n",
    "    # print(fit)\n",
    "   \n",
    "    return c2_src\n",
    "def test_NPoint_snk(tag,data,prior):\n",
    "    # tag = 'PS'\n",
    "    nt = data[tag].shape\n",
    "    data_ = data.pop(tag)\n",
    "    c2_snk = cf.C_2pt(tag, data_)\n",
    "    # print(c2_snk)\n",
    "    # assert len(c2_snk) == nt[0],\\\n",
    "    #     \"Unexpected len(c2_snk)\"\n",
    "    # assert len(c2_snk[:]) == nt[0],\\\n",
    "    #     \"Unexpected len(c2_snk[:])\"\n",
    "    # Nstates = collections.namedtuple('NStates', ['n', 'no', 'm', 'mo'], defaults=(1, 0, 0, 0))\n",
    "    nstates = Nstates(n=2, no=1)\n",
    "    # n=nstates.n, no=nstates.no\n",
    "    # prior = priors.MesonPriorPDG(nstates, 'pi',a_fm = .09)\n",
    "    \n",
    "    # fitter = C_2pt_Analysis(c2_snk)\n",
    "    # fit = fitter.run_fit()\n",
    "    # print(fit)\n",
    "    \n",
    "    return c2_snk\n",
    "\n",
    "def test_NPoint_3pt(tag,data,c2,c2_src,c2_snk):\n",
    "    # nt = data[tag].shape\n",
    "    # print(nt)\n",
    "\n",
    "    data = data.pop(tag)\n",
    "    c3 = cf.C_3pt(tag, data)\n",
    "    # print(c3.ydict)\n",
    "    # avg = c3.avg(m_src=c2_src.mass, m_snk=c2_snk.mass)\n",
    "    # prior = priors.vmatrix(nstates)\n",
    "    # Nstates = collections.namedtuple('NStates', ['n', 'no', 'm', 'mo'], defaults=(1, 0, 0, 0))\n",
    "    nstates = Nstates(n=2, no=1,m=1,mo=0)\n",
    "    # print(nstates)\n",
    "    avg = c3.avg(m_src=c2_src.mass, m_snk=c2_snk.mass)\n",
    "    # print(avg)\n",
    "    # fitter = C_3pt_Analysis(data,c2,c2_snk,c2_src,tags=tag)\n",
    "    # fit = fitter.run_sequential_fits(nstates)\n",
    "    # print(fit)\n",
    "    return c3\n",
    "import fitter.test_corr as run \n",
    "print(run.C2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "t_sink keys must be integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-47350a447a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_sink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_sink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t_sink keys must be integers.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: t_sink keys must be integers."
     ]
    }
   ],
   "source": [
    "for t_sink in out.keys():\n",
    "    print(t_sink)\n",
    "    if not isinstance(t_sink, int):\n",
    "        raise TypeError(\"t_sink keys must be integers.\")\n",
    "    if nt is None:\n",
    "        try:\n",
    "            np.unique([len(arr) for arr in out.values()]).item()\n",
    "        except ValueError as _:\n",
    "            raise ValueError(\"Values in ydict must have same length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to Series, length must be 1: given 160",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2460c1fa4608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr_functions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_2pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'corr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/c51_corr_analysis/src/fitter/corr_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tag, ydata, noise_threshy, skip_fastfit, **time_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfastfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             self.fastfit = fastfit.FastFit(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mtp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/c51_corr_analysis/src/fitter/fastfit.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, ampl, dE, E, s, tp, tmin, svdcut, osc, nterm)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Marginalize over the exicted states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0md_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarginalized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Average over the remaining plateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__sub__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__rsub__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6948\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_prepare_scalar_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6950\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign_method_FRAME\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6952\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_frame_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36malign_method_FRAME\u001b[0;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mto_series\u001b[0;34m(right)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    240\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgiven_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to coerce to Series, length must be 1: given 160"
     ]
    }
   ],
   "source": [
    "import fitter.corr_functions as cf \n",
    "cf.C_2pt(tag='corr',ydata=corr_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/home/gbradley/c51_corr_analysis/tests/a09m135_s_avg_srcs0-15.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8fc4faa8384a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# top_keys = [key for key in h5f.keys()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# for top_key in top_keys:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 533\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/home/gbradley/c51_corr_analysis/tests/a09m135_s_avg_srcs0-15.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# h5fname = '/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_4002.ama.h5'\n",
    "\n",
    "\n",
    "   \n",
    "with h5py.File(h5fname, 'r') as h5f:\n",
    "    # top_keys = [key for key in h5f.keys()]\n",
    "    # for top_key in top_keys:\n",
    "    #     group = h5f[top_key]\n",
    "    #     group['10'] = group['3pt_tsep10']\n",
    "    data = {}\n",
    "    dsets = get_dsets(h5f)\n",
    "    # print(dsets)\n",
    "    for key in dsets.keys():\n",
    "        # print(key)\n",
    "        data[key] = h5f[key][:]\n",
    "    print(data['2pt/ext_current/src5.0_snk5.0/ext_axial_A1_A1/C13.b_4002/AMA'])\n",
    "    # [val for key,val in dsets.items() if key in mystring]\n",
    "    # print(val[key])\n",
    "    # for key in dsets.keys():\n",
    "    #     if key in \n",
    "        \n",
    "            \n",
    "    #     dset = ifile['data']\n",
    "    #     for key in dset.keys():\n",
    "    #         data[key] = ifile['data'][key][:]\n",
    "    # for key in ['13','14','15','16']:\n",
    "    #     data[int(key)] = data.pop(key)\n",
    "\n",
    "    # return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import fitter.corr_functions as cf\n",
    "# import fitter.fit_twopt\n",
    "\n",
    "directory = '/home/gbradley/c51_corr_analysis/tests/data/C13/'\n",
    "N_cnf = len([name for name in os.listdir(directory) if os.path.isfile(name)])\n",
    "\n",
    "dirs = os.listdir( directory )\n",
    "\n",
    "cnf_abbr = [files.split(\".ama.h5\",0) for files in dirs]\n",
    "\n",
    "# data_file_list = os.path.realpath(dirs)\n",
    "data_file_list = list()\n",
    "for dirpath,_,filenames in os.walk(directory):\n",
    "    for f in filenames:\n",
    "        data_file_list.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "file = data_file_list[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUCL: nucleon\n",
    "U: quark bilinear operator inserted on up-quark; D will be used for down-quark\n",
    "MIXED: \"mixed\" type of spin projection is used\n",
    "NONREL: non-relativistic proton is used\n",
    "l0:  when inserting the quark bilinear oprator, the separation of the quarks of the bilinear operator is zero (local operator); you might see some l1 (quark bilinear operator separated by 1 lattice unit) data as well\n",
    "g13: the gamma matrix of the quark bilinear operator is \"13\" in Chroma convention. Page 6 and 7 of the attached pdf shows the Chroma gamma matrix convention and its indexing; their indexing is summarized below:\n",
    " \n",
    "0: scalar; I\n",
    "15: pseudoscalar; g_5\n",
    "1: vector;  g_x\n",
    "2: vector;  g_y\n",
    "4: vector;  g_z\n",
    "8: vector;  g_t\n",
    "14: axial;   g_x g_5\n",
    "13: axial;  -g_y g_5\n",
    "11: axial;   g_z g_5\n",
    "7: axial;  -g_t g_5\n",
    "9: tensor;  g_x g_t\n",
    "10: tensor;  g_y g_t\n",
    "12: tensor;  g_z g_t\n",
    "3: tensor;  g_x g_y\n",
    "6: tensor;  g_y g_z\n",
    "5: tensor;  g_x g_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tsep': '12', 'quark': 'D', 'l': '0', 'g': '0', 'src': '5.0', 'snk': '5.0', 'qz': '+0', 'qy': '+0', 'qx': '+0'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "string = (\n",
    "    \"3pt_tsep12/NUCL_D_MIXED_NONREL_l0_g0/src5.0_snk5.0/qz+0_qy+0_qx+0/C13.b_5682/AMA\"\n",
    ")\n",
    "\n",
    "patterns = [\n",
    "    \"3pt\",\n",
    "    \"_tsep(?P<tsep>[0-9]|[0-9]+)\",  # must match `_tsep` and stores the following numbers (any length)\n",
    "    \"/NUCL_(?P<quark>U|D)\",  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\",  # Not sure if this changes. Not stored for now\n",
    "    \"_l(?P<l>[0-9]+)\",  # action parameters?\n",
    "    \"_g(?P<g>[0-15]+)\",\n",
    "    \"/src(?P<src>[0-9\\.]+)\",  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\",  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"/qz(?P<qz>[\\+\\-0-9]+)\", \n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\", \n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\", \n",
    "    \n",
    "]\n",
    "\n",
    "for n in range(len(patterns)):\n",
    "    pattern = \"\".join(patterns[:n+1])\n",
    "    match = re.match(pattern, string)\n",
    "    if not match:\n",
    "        print(pattern)\n",
    "        break\n",
    "\n",
    "if match:\n",
    "    print(match.groupdict())\n",
    "# 3pt_tsep8/NUCL_U_MIXED_NONREL_l0_g9/src5.0_snk5.0/qz-3_qy+0_qx+1/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A1_A1/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A1_A1_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A3_P_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A4_A4_px3_py1_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A4_P/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A4_P_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_vector_T12_T12_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current_SP/src5.0_snk5.0/ext_vector_V2_V2_px1_py1_pz1/C13.b_5682/AMA\n",
    "# 2pt/pion/src5.0_snk5.0/pion_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/pion_SP/src5.0_snk5.0/pion_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/proton/src5.0_snk5.0/proton_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/proton_SP/src5.0_snk5.0/proton_px1_py0_pz0/C13.b_5682/AMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_baryon_tag(datatag):\n",
    "    ''' Given a datatag, return dict with keys to pass into fitter  '''\n",
    "    datatag_split = datatag.split('/')\n",
    "    corr_type     = datatag_split[0]\n",
    "    tsep          = int(corr_type.split('_tsep')[1])\n",
    "    buffer        =  datatag_split[1]\n",
    "    channel       = buffer.split('_')[0]\n",
    "    quark_ins       = buffer.split('_')[1]\n",
    "    spin_proj       = buffer.split('_')[2]\n",
    "    quark_sep       = buffer.split('_')[3]\n",
    "    gamma           = buffer.split('_')[4] #gamma matrix of quark bilinear operator in the CHROMA convention , value accessed via dict\n",
    "    src_snk_sep     = datatag_split[2]\n",
    "    mom         = datatag_split[3]\n",
    "    mom0       = mom.split('_')[0]\n",
    "    mom1       = mom.split('_')[1]\n",
    "    mom2       = mom.split('_')[2]\n",
    "    momentum        = (mom0,mom1,mom2)\n",
    "    config   = datatag_split[4]\n",
    "\n",
    "    data_dict = dict()\n",
    "    data_dict['corr_type']   = corr_type\n",
    "    data_dict['tsep']        = tsep\n",
    "    data_dict['buffer']      = buffer\n",
    "    data_dict['channel']     = channel\n",
    "    data_dict['quark_ins']   = quark_ins\n",
    "    data_dict['spin_proj']   = spin_proj\n",
    "    data_dict['quark_sep']   = quark_sep\n",
    "    data_dict['gamma']       = gamma\n",
    "    data_dict['src_snk_sep'] = src_snk_sep\n",
    "    data_dict['mom']         = momentum\n",
    "    data_dict['config']      = config\n",
    "    return data_dict\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corr_type': '3pt_tsep12',\n",
       " 'tsep': 12,\n",
       " 'buffer': 'NUCL_D_MIXED_NONREL_l0_g0',\n",
       " 'channel': 'NUCL',\n",
       " 'quark_ins': 'D',\n",
       " 'spin_proj': 'MIXED',\n",
       " 'quark_sep': 'NONREL',\n",
       " 'gamma': 'l0',\n",
       " 'src_snk_sep': 'src5.0_snk5.0',\n",
       " 'mom': ('qz+0', 'qy+0', 'qx+0'),\n",
       " 'config': 'C13.b_5682'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parse_baryon_tag(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_2pt_spec(params,dsets,h5_file =None,collect=False):\n",
    "    params = dict(params)\n",
    "    params['buffer'] = pion \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"tsep\", \"quark\", \"l\", \"g\", \"src\", \"snk\",\"qz\",\"qy\",\"qx\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-16 20:27:20,527|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_5682.ama.h5`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tsep</th>\n",
       "      <th>g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tsep</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tsep   g\n",
       "tsep   NaN NaN\n",
       "g      NaN NaN"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames = []\n",
    "\n",
    "with h5py.File(file, \"r\") as h5f:\n",
    "    dsets = get_dsets(h5f)\n",
    "    # print(dsets)\n",
    "    for key, dset in dsets.items():\n",
    "        match = re.search(pattern, string)\n",
    "        if match:\n",
    "            info = match.groupdict()\n",
    "            # print(info)\n",
    "#             corr = info.pop(\"tsep\")\n",
    "\n",
    "            quark = info.pop(\"quark\")\n",
    "            # print(quark)\n",
    "            info[\"quark\"] = quark[0]\n",
    "# #             # info[\"parity\"] = -1 if len(nucleon_parity) == 2 else 1\n",
    "            \n",
    "            gamma = info.pop(\"g\")\n",
    "            if gamma in [\"g1\",\"g2\",\"g4\",\"g8\"]:\n",
    "                info[\"gamma\"] = \"vector\"\n",
    "            elif gamma in [\"g0\"]:\n",
    "                info[\"gamma\"] = \"scalar\"\n",
    "            elif gamma in [\"g5\"]:\n",
    "                info[\"gamma\"] = \"pseudoscalar\"\n",
    "            elif gamma in [\"g14\",\"g13\",\"g11\",\"g7\"]:\n",
    "                info[\"gamma\"] = \"axial\"\n",
    "            elif gamma in [\"g14\",\"g13\",\"g11\",\"g7\"]:\n",
    "                info[\"gamma\"] = \"axial\"\n",
    "            elif gamma in [\"g9\",\"g10\",\"g12\",\"g3\",\"g6\",\"g5\"]:\n",
    "                info[\"gamma\"] = \"tensor\"\n",
    "\n",
    "            # current_key = key.replace(\"g\", \"\")\n",
    "            curr_dset = h5f[key]\n",
    "\n",
    "            cfgs = dset[:]\n",
    "            corr = (\n",
    "                curr_dset[()].real \n",
    "                # if info[\"current\"] in [\"V4\"] else curr_dset[()].imag\n",
    "            )\n",
    "            # print(corr.shape[-1])\n",
    "            ts = range(corr.shape[-1])\n",
    "            # print(ts)\n",
    "            tmp_df = (\n",
    "                pd.DataFrame(index=cfgs, columns=ts, data=corr)\n",
    "                .unstack()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"level_0\": \"tsep\", \"level_1\": \"cfg\", 0: \"corr\"})\n",
    "            )\n",
    "            # data_frames = {}\n",
    "            ydict = {}\n",
    "            for key, val in info.items():\n",
    "                tmp_df[key] = val\n",
    "            data_frames.append(tmp_df.astype({\"tsep\": int}))\n",
    "            # print(data_frames)\n",
    "\n",
    "\n",
    "df = pd.concat(\n",
    "    data_frames, \n",
    "    ignore_index=True, \n",
    ").reindex(columns, axis=1).sort_values(columns).reset_index(drop=True)\n",
    "\n",
    "# df.head()\n",
    "# print(df.keys())\n",
    "# for 'tsep' in df.keys():\n",
    "#     if not isinstance(tsep, int):\n",
    "#                 raise TypeError(\"t_sink keys must be integers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          12\n",
      "1          12\n",
      "2          12\n",
      "3          12\n",
      "4          12\n",
      "           ..\n",
      "3729211    12\n",
      "3729212    12\n",
      "3729213    12\n",
      "3729214    12\n",
      "3729215    12\n",
      "Name: tsep, Length: 3729216, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import corr_functions as cf \n",
    "print(df.tsep)\n",
    "ydict = {tag: val for tag, val in df.items() if isinstance(tag, int)}\n",
    "ydict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistical average ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_data(arg):\n",
    "    corr_avg = gvar.dataset.avg_data(\n",
    "        arg.pivot(index=\"cfg\", columns=\"t\", values=\"corr\").values\n",
    "    )\n",
    "    return pd.Series(corr_avg)\n",
    "\n",
    "\n",
    "group = isospin_spin_parity_avg_df.groupby([\"nucleon\", \"current\", \"tsep\"])\n",
    "corr_df = (\n",
    "    group.apply(avg_data)\n",
    "    .reset_index(level=-1)\n",
    "    .rename(columns={\"level_3\": \"t\", 0: \"corr\"})\n",
    "    .reset_index()\n",
    "    .set_index([\"nucleon\", \"current\", \"tsep\", \"t\"])\n",
    ")\n",
    "\n",
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum average ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_avg(h5_data,state,mom_lst,weights=False):\n",
    "    '''\n",
    "    perform a momentum average of a state from an open h5 file\n",
    "    data file is assumed to be of shape [Nt,Nz,Ny,Nx,[re,im]]\n",
    "    data_mom = h5_data[state][:,pz,py,px]\n",
    "    '''\n",
    "    d_lst = []\n",
    "    w = []\n",
    "    for mom in mom_lst:\n",
    "        px,py,pz = mom['momentum']\n",
    "        w.append(mom['weight'])\n",
    "        #print(state)\n",
    "        d_lst.append(h5_data[state][:,pz,py,px])\n",
    "    d_lst = np.array(d_lst)\n",
    "    w = np.array(w)\n",
    "    if weights:\n",
    "        for wi,we in enumerate(w):\n",
    "            d_lst[wi] = we*d_lst[wi]\n",
    "        d_avg = np.sum(d_lst,axis=0) / np.sum(w)\n",
    "    else:\n",
    "        d_avg = np.mean(d_lst,axis=0)\n",
    "    return d_avg\n",
    "# mom_avg('/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_5178.ama.h5', state, mom_lst)\n",
    "\n",
    "mom_lst = []\n",
    "for px in range(-2,3):\n",
    "    for py in range(-2,3):\n",
    "        for pz in range(-2,3):\n",
    "            if px**2 + py**2 + pz**2 <= 5:\n",
    "                mom_lst.append('pz'+str(pz)+'_py'+str(py)+'_px'+str(px))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

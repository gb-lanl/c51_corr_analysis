{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gvar as gv\n",
    "import re \n",
    "import pandas as pd \n",
    "import sys\n",
    "import copy\n",
    "import tables as h5\n",
    "import h5py\n",
    "import os \n",
    "import time\n",
    "import re\n",
    "sys.path.insert(0, '/home/gbradley/nucleon_elastic_FF')\n",
    "from nucleon_elastic_ff.data.h5io import get_dsets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-07 16:57:06,006|lqcd correlator analysis@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_4002.ama.h5`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-2.58211152e-04, -1.30685940e-15) ( 5.87860783e-05,  1.41900927e-14)\n",
      " ( 2.57692208e-05, -2.63309518e-15) ( 1.13296507e-05,  4.67235660e-16)\n",
      " ( 5.59413382e-06,  3.97957074e-15) ( 2.38318088e-06,  3.10596431e-15)\n",
      " ( 1.14248262e-06,  2.60821298e-16) ( 5.90481965e-07, -9.83484766e-16)\n",
      " ( 1.60438565e-07, -6.76532309e-16) ( 7.70157259e-08, -1.51733247e-15)\n",
      " ( 1.56569742e-07,  3.28791731e-17) ( 6.94757076e-08, -7.04444216e-16)\n",
      " ( 1.97736845e-08,  2.10743094e-16) (-2.90964137e-08, -7.25096198e-17)\n",
      " (-2.23251868e-08,  4.06067857e-17) (-9.99152606e-09,  1.87443733e-16)\n",
      " (-6.44054813e-10,  2.11968486e-16) ( 2.47886818e-09,  1.49763737e-16)\n",
      " ( 2.23477394e-09,  9.59116581e-17) (-4.31796012e-10, -4.06884055e-17)\n",
      " (-1.01335198e-08,  1.59745027e-16) (-5.28003747e-09,  3.49200185e-17)\n",
      " ( 3.48499936e-09, -8.23085473e-17) (-1.13816400e-08,  5.71131949e-17)]\n"
     ]
    }
   ],
   "source": [
    "h5fname = '/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_4002.ama.h5'\n",
    "\n",
    "\n",
    "   \n",
    "with h5py.File(h5fname, 'r') as h5f:\n",
    "    # top_keys = [key for key in h5f.keys()]\n",
    "    # for top_key in top_keys:\n",
    "    #     group = h5f[top_key]\n",
    "    #     group['10'] = group['3pt_tsep10']\n",
    "    data = {}\n",
    "    dsets = get_dsets(h5f)\n",
    "    # print(dsets)\n",
    "    for key in dsets.keys():\n",
    "        # print(key)\n",
    "        data[key] = h5f[key][:]\n",
    "    print(data['2pt/ext_current/src5.0_snk5.0/ext_axial_A1_A1/C13.b_4002/AMA'])\n",
    "    # [val for key,val in dsets.items() if key in mystring]\n",
    "    # print(val[key])\n",
    "    # for key in dsets.keys():\n",
    "    #     if key in \n",
    "        \n",
    "            \n",
    "    #     dset = ifile['data']\n",
    "    #     for key in dset.keys():\n",
    "    #         data[key] = ifile['data'][key][:]\n",
    "    # for key in ['13','14','15','16']:\n",
    "    #     data[int(key)] = data.pop(key)\n",
    "\n",
    "    # return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import fitter.corr_functions as cf\n",
    "# import fitter.fit_twopt\n",
    "\n",
    "directory = '/home/gbradley/c51_corr_analysis/tests/data/C13/'\n",
    "N_cnf = len([name for name in os.listdir(directory) if os.path.isfile(name)])\n",
    "\n",
    "dirs = os.listdir( directory )\n",
    "\n",
    "cnf_abbr = [files.split(\".ama.h5\",0) for files in dirs]\n",
    "\n",
    "# data_file_list = os.path.realpath(dirs)\n",
    "data_file_list = list()\n",
    "for dirpath,_,filenames in os.walk(directory):\n",
    "    for f in filenames:\n",
    "        data_file_list.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "file = data_file_list[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUCL: nucleon\n",
    "U: quark bilinear operator inserted on up-quark; D will be used for down-quark\n",
    "MIXED: \"mixed\" type of spin projection is used\n",
    "NONREL: non-relativistic proton is used\n",
    "l0:  when inserting the quark bilinear oprator, the separation of the quarks of the bilinear operator is zero (local operator); you might see some l1 (quark bilinear operator separated by 1 lattice unit) data as well\n",
    "g13: the gamma matrix of the quark bilinear operator is \"13\" in Chroma convention. Page 6 and 7 of the attached pdf shows the Chroma gamma matrix convention and its indexing; their indexing is summarized below:\n",
    " \n",
    "0: scalar; I\n",
    "15: pseudoscalar; g_5\n",
    "1: vector;  g_x\n",
    "2: vector;  g_y\n",
    "4: vector;  g_z\n",
    "8: vector;  g_t\n",
    "14: axial;   g_x g_5\n",
    "13: axial;  -g_y g_5\n",
    "11: axial;   g_z g_5\n",
    "7: axial;  -g_t g_5\n",
    "9: tensor;  g_x g_t\n",
    "10: tensor;  g_y g_t\n",
    "12: tensor;  g_z g_t\n",
    "3: tensor;  g_x g_y\n",
    "6: tensor;  g_y g_z\n",
    "5: tensor;  g_x g_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tsep': '12', 'quark': 'D', 'l': '0', 'g': '0', 'src': '5.0', 'snk': '5.0', 'qz': '+0', 'qy': '+0', 'qx': '+0'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "string = (\n",
    "    \"3pt_tsep12/NUCL_D_MIXED_NONREL_l0_g0/src5.0_snk5.0/qz+0_qy+0_qx+0/C13.b_5682/AMA\"\n",
    ")\n",
    "\n",
    "patterns = [\n",
    "    \"3pt\",\n",
    "    \"_tsep(?P<tsep>[0-9]|[0-9]+)\",  # must match `_tsep` and stores the following numbers (any length)\n",
    "    \"/NUCL_(?P<quark>U|D)\",  # Store U or D in quark\n",
    "    \"_MIXED_NONREL\",  # Not sure if this changes. Not stored for now\n",
    "    \"_l(?P<l>[0-9]+)\",  # action parameters?\n",
    "    \"_g(?P<g>[0-15]+)\",\n",
    "    \"/src(?P<src>[0-9\\.]+)\",  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"_snk(?P<snk>[0-9\\.]+)\",  # Stores numbers + . to store decimals. Must escape .\n",
    "    \"/qz(?P<qz>[\\+\\-0-9]+)\", \n",
    "    \"_qy(?P<qy>[\\+\\-0-9]+)\", \n",
    "    \"_qx(?P<qx>[\\+\\-0-9]+)\", \n",
    "    \n",
    "]\n",
    "\n",
    "for n in range(len(patterns)):\n",
    "    pattern = \"\".join(patterns[:n+1])\n",
    "    match = re.match(pattern, string)\n",
    "    if not match:\n",
    "        print(pattern)\n",
    "        break\n",
    "\n",
    "if match:\n",
    "    print(match.groupdict())\n",
    "# 3pt_tsep8/NUCL_U_MIXED_NONREL_l0_g9/src5.0_snk5.0/qz-3_qy+0_qx+1/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A1_A1/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A1_A1_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A3_P_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A4_A4_px3_py1_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A4_P/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_axial_A4_P_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current/src5.0_snk5.0/ext_vector_T12_T12_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/ext_current_SP/src5.0_snk5.0/ext_vector_V2_V2_px1_py1_pz1/C13.b_5682/AMA\n",
    "# 2pt/pion/src5.0_snk5.0/pion_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/pion_SP/src5.0_snk5.0/pion_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/proton/src5.0_snk5.0/proton_px1_py0_pz0/C13.b_5682/AMA\n",
    "# 2pt/proton_SP/src5.0_snk5.0/proton_px1_py0_pz0/C13.b_5682/AMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_baryon_tag(datatag):\n",
    "    datatag_split = datatag.split('/')\n",
    "    corr_type     = datatag_split[0]\n",
    "    tsep          = int(corr_type.split('_tsep')[1])\n",
    "    buffer        =  datatag_split[1]\n",
    "    channel       = buffer.split('_')[0]\n",
    "    quark_ins       = buffer.split('_')[1]\n",
    "    spin_proj       = buffer.split('_')[2]\n",
    "    quark_sep       = buffer.split('_')[3]\n",
    "    gamma           = buffer.split('_')[4] #gamma matrix of quark bilinear operator in the CHROMA convention , value accessed via dict\n",
    "    src_snk_sep     = datatag_split[2]\n",
    "    mom         = datatag_split[3]\n",
    "    mom0       = mom.split('_')[0]\n",
    "    mom1       = mom.split('_')[1]\n",
    "    mom2       = mom.split('_')[2]\n",
    "    momentum        = (mom0,mom1,mom2)\n",
    "    config   = datatag_split[4]\n",
    "\n",
    "    data_dict = dict()\n",
    "    data_dict['corr_type']   = corr_type\n",
    "    data_dict['tsep']        = tsep\n",
    "    data_dict['buffer']      = buffer\n",
    "    data_dict['channel']     = channel\n",
    "    data_dict['quark_ins']   = quark_ins\n",
    "    data_dict['spin_proj']   = spin_proj\n",
    "    data_dict['quark_sep']   = quark_sep\n",
    "    data_dict['gamma']       = gamma\n",
    "    data_dict['src_snk_sep'] = src_snk_sep\n",
    "    data_dict['mom']         = momentum\n",
    "    data_dict['config']      = config\n",
    "    return data_dict\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corr_type': '3pt_tsep12',\n",
       " 'tsep': 12,\n",
       " 'buffer': 'NUCL_D_MIXED_NONREL_l0_g0',\n",
       " 'channel': 'NUCL',\n",
       " 'quark_ins': 'D',\n",
       " 'spin_proj': 'MIXED',\n",
       " 'quark_sep': 'NONREL',\n",
       " 'gamma': 'l0',\n",
       " 'src_snk_sep': 'src5.0_snk5.0',\n",
       " 'mom': ('qz+0', 'qy+0', 'qx+0'),\n",
       " 'config': 'C13.b_5682'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_baryon_tag(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"tsep\", \"quark\", \"l\", \"g\", \"src\", \"snk\",\"qz\",\"qy\",\"qx\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-04 13:40:32,887|nucleon_elastic_ff@INFO] Locating all dsets of h5 file `/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_5682.ama.h5`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-2.56356869e-04, -1.11207678e-14) ( 6.19844931e-05, -5.57827152e-15)\n",
      " ( 2.80756822e-05, -4.45528297e-15) ( 1.28634833e-05,  1.58291252e-15)\n",
      " ( 5.51984960e-06, -1.83916225e-17) ( 2.06134187e-06, -1.83563147e-15)\n",
      " ( 8.22243347e-07,  1.16850159e-15) ( 3.55047819e-07,  2.13496274e-15)\n",
      " (-8.82941188e-08,  1.21976550e-15) (-1.26974504e-07, -7.16024162e-16)\n",
      " (-1.10442904e-07,  5.56118423e-16) (-8.31974471e-08,  1.46340611e-16)\n",
      " ( 3.73264712e-08, -2.94597794e-16) ( 9.58739622e-08,  1.66116448e-16)\n",
      " ( 8.90409021e-08,  3.10279445e-16) ( 1.33651669e-08, -2.56066583e-16)\n",
      " ( 6.61094425e-08, -1.63885921e-16) (-4.16672070e-08,  3.17653449e-16)\n",
      " (-7.37063703e-08, -3.28802309e-16) (-5.32416570e-08,  6.22143052e-17)\n",
      " (-3.24150229e-08,  1.05534429e-16) (-3.21676882e-09, -3.78036628e-17)\n",
      " (-4.83421180e-09, -8.44932836e-17) (-1.37609513e-08, -6.75218136e-17)]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-0adcf03c696d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mtmp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"tsep\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data_frames = []\n",
    "\n",
    "with h5py.File(file, \"r\") as h5f:\n",
    "    dsets = get_dsets(h5f)\n",
    "    # print(dsets)\n",
    "    for key, dset in dsets.items():\n",
    "        match = re.search(pattern, string)\n",
    "        if match:\n",
    "            info = match.groupdict()\n",
    "            # print(info)\n",
    "#             corr = info.pop(\"tsep\")\n",
    "\n",
    "            quark = info.pop(\"quark\")\n",
    "            # print(quark)\n",
    "            info[\"quark\"] = quark[0]\n",
    "# #             # info[\"parity\"] = -1 if len(nucleon_parity) == 2 else 1\n",
    "            \n",
    "            gamma = info.pop(\"g\")\n",
    "            if gamma in [\"g1\",\"g2\",\"g4\",\"g8\"]:\n",
    "                info[\"gamma\"] = \"vector\"\n",
    "            elif gamma in [\"g0\"]:\n",
    "                info[\"gamma\"] = \"scalar\"\n",
    "            elif gamma in [\"g5\"]:\n",
    "                info[\"gamma\"] = \"pseudoscalar\"\n",
    "            elif gamma in [\"g14\",\"g13\",\"g11\",\"g7\"]:\n",
    "                info[\"gamma\"] = \"axial\"\n",
    "            elif gamma in [\"g14\",\"g13\",\"g11\",\"g7\"]:\n",
    "                info[\"gamma\"] = \"axial\"\n",
    "            elif gamma in [\"g9\",\"g10\",\"g12\",\"g3\",\"g6\",\"g5\"]:\n",
    "                info[\"gamma\"] = \"tensor\"\n",
    "\n",
    "            # current_key = key.replace(\"g\", \"\")\n",
    "            curr_dset = h5f[key]\n",
    "\n",
    "            cfgs = dset[:]\n",
    "            corr = (\n",
    "                curr_dset[()].real \n",
    "                # if info[\"current\"] in [\"V4\"] else curr_dset[()].imag\n",
    "            )\n",
    "            # print(corr.shape[-1])\n",
    "            ts = range(corr.shape[-1])\n",
    "            # print(ts)\n",
    "            tmp_df = (\n",
    "                pd.DataFrame(index=cfgs, columns=ts, data=corr)\n",
    "                .unstack()\n",
    "                .reset_index()\n",
    "                .rename(columns={\"level_0\": \"tsep\", \"level_1\": \"cfg\", 0: \"corr\"})\n",
    "            )\n",
    "            # data_frames = {}\n",
    "            ydict = {}\n",
    "            for key, val in info.items():\n",
    "                tmp_df[key] = val\n",
    "            data_frames.append(tmp_df.astype({\"tsep\": int}))\n",
    "            print(data_frames)\n",
    "\n",
    "\n",
    "# df = pd.concat(\n",
    "#     data_frames, \n",
    "#     ignore_index=True, \n",
    "# ).reindex(columns, axis=1).sort_values(columns).reset_index(drop=True)\n",
    "# print(df.type())\n",
    "# # df.head()\n",
    "# print(df.keys())\n",
    "# for 'tsep' in df.keys():\n",
    "#     if not isinstance(tsep, int):\n",
    "#                 raise TypeError(\"t_sink keys must be integers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          12\n",
      "1          12\n",
      "2          12\n",
      "3          12\n",
      "4          12\n",
      "           ..\n",
      "3729211    12\n",
      "3729212    12\n",
      "3729213    12\n",
      "3729214    12\n",
      "3729215    12\n",
      "Name: tsep, Length: 3729216, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import corr_functions as cf \n",
    "print(df.tsep)\n",
    "ydict = {tag: val for tag, val in df.items() if isinstance(tag, int)}\n",
    "ydict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistical average ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_data(arg):\n",
    "    corr_avg = gvar.dataset.avg_data(\n",
    "        arg.pivot(index=\"cfg\", columns=\"t\", values=\"corr\").values\n",
    "    )\n",
    "    return pd.Series(corr_avg)\n",
    "\n",
    "\n",
    "group = isospin_spin_parity_avg_df.groupby([\"nucleon\", \"current\", \"tsep\"])\n",
    "corr_df = (\n",
    "    group.apply(avg_data)\n",
    "    .reset_index(level=-1)\n",
    "    .rename(columns={\"level_3\": \"t\", 0: \"corr\"})\n",
    "    .reset_index()\n",
    "    .set_index([\"nucleon\", \"current\", \"tsep\", \"t\"])\n",
    ")\n",
    "\n",
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum average ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_avg(h5_data,state,mom_lst,weights=False):\n",
    "    '''\n",
    "    perform a momentum average of a state from an open h5 file\n",
    "    data file is assumed to be of shape [Nt,Nz,Ny,Nx,[re,im]]\n",
    "    data_mom = h5_data[state][:,pz,py,px]\n",
    "    '''\n",
    "    d_lst = []\n",
    "    w = []\n",
    "    for mom in mom_lst:\n",
    "        px,py,pz = mom['momentum']\n",
    "        w.append(mom['weight'])\n",
    "        #print(state)\n",
    "        d_lst.append(h5_data[state][:,pz,py,px])\n",
    "    d_lst = np.array(d_lst)\n",
    "    w = np.array(w)\n",
    "    if weights:\n",
    "        for wi,we in enumerate(w):\n",
    "            d_lst[wi] = we*d_lst[wi]\n",
    "        d_avg = np.sum(d_lst,axis=0) / np.sum(w)\n",
    "    else:\n",
    "        d_avg = np.mean(d_lst,axis=0)\n",
    "    return d_avg\n",
    "# mom_avg('/home/gbradley/c51_corr_analysis/tests/data/C13/C13-b_5178.ama.h5', state, mom_lst)\n",
    "\n",
    "mom_lst = []\n",
    "for px in range(-2,3):\n",
    "    for py in range(-2,3):\n",
    "        for pz in range(-2,3):\n",
    "            if px**2 + py**2 + pz**2 <= 5:\n",
    "                mom_lst.append('pz'+str(pz)+'_py'+str(py)+'_px'+str(px))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
